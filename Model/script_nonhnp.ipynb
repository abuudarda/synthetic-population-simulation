{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToUse=[\"CDIVMSAR\", \"CENSUS_D\", \"CENSUS_R\", \"DRVRCNT\", \"EDUC\", \"HHRESP\", \"HHSIZE\", \"HHSTATE\", \"HHSTFIPS\", \"HHVEHCNT\", \"HH_CBSA\", \"HH_HISP\", \"HH_RACE\", \"HOMEOWN\", \"HOUSEID\", \"HHFAMINC\", \"MSACAT\", \"MSASIZE\", \"NUMADLT\", \"PRMACT\", \"PROXY\", \"RAIL\", \"R_AGE\", \"R_AGE_IMP\", \"R_SEX\", \"R_SEX_IMP\", \"SMPLSRCE\", \"URBAN\", \"URBANSIZE\", \"URBRUR\", \"WRKCOUNT\",\"TRIPPURP\"]\n",
    "df = pd.read_csv('C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\NHTS Data Parser\\\\HH Data Parser\\\\trippub.csv')\n",
    "X = df.drop(columns=['TRIPPURP'])\n",
    "X=df.drop(columns=columnsToUse)\n",
    "y = df['TRIPPURP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRPMILES    float64\n",
      "TRIPPURP     object\n",
      "VMT_MILE    float64\n",
      "HHSTATE      object\n",
      "GASPRICE    float64\n",
      "HH_CBSA      object\n",
      "WTTRDFIN    float64\n",
      "TRPMILAD    float64\n",
      "OBHUR        object\n",
      "DBHUR        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_int64_columns = df.dtypes[df.dtypes != 'int64']\n",
    "print(non_int64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# X['TRIPPURP'] = label_encoder.fit_transform(X['TRIPPURP'])\n",
    "# X['HHSTATE'] = label_encoder.fit_transform(X['HHSTATE'])\n",
    "# X['HH_CBSA'] = label_encoder.fit_transform(X['HH_CBSA'])\n",
    "X['OBHUR'] = label_encoder.fit_transform(X['OBHUR'])\n",
    "X['DBHUR'] = label_encoder.fit_transform(X['DBHUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the target variable using LabelEncoder\n",
    "y_label_encoder = LabelEncoder()\n",
    "y_encoded = y_label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the target variable to one-hot encoded format\n",
    "num_classes = len(y_label_encoder.classes_)\n",
    "y_one_hot = pd.get_dummies(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "# X_train=X.astype('float64')\n",
    "num_classes\n",
    "# Standardize the features (optional, but often recommended for neural networks)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738857, 83)\n",
      "(738857, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 712us/step - loss: 0.2509 - accuracy: 0.9111 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 16s 705us/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.0362 - val_accuracy: 0.9931\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 16s 703us/step - loss: 0.0417 - accuracy: 0.9883 - val_loss: 0.0235 - val_accuracy: 0.9960\n",
      "5773/5773 [==============================] - 3s 509us/step - loss: 0.0235 - accuracy: 0.9960\n",
      "Test loss: 0.023497819900512695\n",
      "Test accuracy: 0.9959830045700073\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add layers to the model\n",
    "# model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=3, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "# model.fit(X_train, y, epochs=3, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRPMILES    float64\n",
      "TRIPPURP     object\n",
      "VMT_MILE    float64\n",
      "HHSTATE      object\n",
      "GASPRICE    float64\n",
      "HH_CBSA      object\n",
      "WTTRDFIN    float64\n",
      "TRPMILAD    float64\n",
      "OBHUR        object\n",
      "DBHUR        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_int64_columns = df.dtypes[df.dtypes != 'int64']\n",
    "print(non_int64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 729us/step - loss: 0.2841 - accuracy: 0.8969 - val_loss: 0.0614 - val_accuracy: 0.9863\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 729us/step - loss: 0.0516 - accuracy: 0.9845 - val_loss: 0.0403 - val_accuracy: 0.9861\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 736us/step - loss: 0.0374 - accuracy: 0.9889 - val_loss: 0.0202 - val_accuracy: 0.9959\n",
      "5773/5773 [==============================] - 3s 500us/step - loss: 0.0202 - accuracy: 0.9959\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 714us/step - loss: 0.2344 - accuracy: 0.9185 - val_loss: 0.0492 - val_accuracy: 0.9884\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 728us/step - loss: 0.0492 - accuracy: 0.9856 - val_loss: 0.0244 - val_accuracy: 0.9957\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 18s 765us/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.0169 - val_accuracy: 0.9966\n",
      "5773/5773 [==============================] - 4s 751us/step - loss: 0.0169 - accuracy: 0.9966\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.2569 - accuracy: 0.9096 - val_loss: 0.0496 - val_accuracy: 0.9862\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 0.0650 - val_accuracy: 0.9742\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0391 - accuracy: 0.9886 - val_loss: 0.0267 - val_accuracy: 0.9931\n",
      "5773/5773 [==============================] - 4s 625us/step - loss: 0.0267 - accuracy: 0.9931\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 817us/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 0.0557 - val_accuracy: 0.9856\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 794us/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 802us/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.0438 - val_accuracy: 0.9875\n",
      "5773/5773 [==============================] - 3s 577us/step - loss: 0.0438 - accuracy: 0.9875\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 799us/step - loss: 0.2886 - accuracy: 0.8959 - val_loss: 0.0771 - val_accuracy: 0.9770\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0555 - accuracy: 0.9840 - val_loss: 0.2271 - val_accuracy: 0.9308\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0199 - val_accuracy: 0.9974\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.0199 - accuracy: 0.9974\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 807us/step - loss: 0.2648 - accuracy: 0.9070 - val_loss: 0.0447 - val_accuracy: 0.9908\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 800us/step - loss: 0.0518 - accuracy: 0.9847 - val_loss: 0.0335 - val_accuracy: 0.9886\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 803us/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 0.0181 - val_accuracy: 0.9973\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.0181 - accuracy: 0.9973\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.2873 - accuracy: 0.8970 - val_loss: 0.0524 - val_accuracy: 0.9848\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 798us/step - loss: 0.0548 - accuracy: 0.9847 - val_loss: 0.0560 - val_accuracy: 0.9812\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 18s 800us/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0265 - val_accuracy: 0.9952\n",
      "5773/5773 [==============================] - 3s 581us/step - loss: 0.0265 - accuracy: 0.9952\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.2757 - accuracy: 0.9042 - val_loss: 0.0673 - val_accuracy: 0.9770\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 807us/step - loss: 0.0496 - accuracy: 0.9858 - val_loss: 0.0360 - val_accuracy: 0.9874\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 805us/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.0335 - val_accuracy: 0.9903\n",
      "5773/5773 [==============================] - 3s 586us/step - loss: 0.0335 - accuracy: 0.9903\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.2714 - accuracy: 0.9031 - val_loss: 0.0751 - val_accuracy: 0.9775\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 800us/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.0331 - val_accuracy: 0.9943\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 803us/step - loss: 0.0409 - accuracy: 0.9883 - val_loss: 0.0255 - val_accuracy: 0.9931\n",
      "5773/5773 [==============================] - 3s 584us/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.2754 - accuracy: 0.9000 - val_loss: 0.0523 - val_accuracy: 0.9883\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.0539 - accuracy: 0.9843 - val_loss: 0.0289 - val_accuracy: 0.9947\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 0.0468 - val_accuracy: 0.9846\n",
      "5773/5773 [==============================] - 3s 583us/step - loss: 0.0468 - accuracy: 0.9846\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 817us/step - loss: 0.2946 - accuracy: 0.8991 - val_loss: 0.0550 - val_accuracy: 0.9921\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.0548 - accuracy: 0.9851 - val_loss: 0.0325 - val_accuracy: 0.9949\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0402 - accuracy: 0.9893 - val_loss: 0.0370 - val_accuracy: 0.9896\n",
      "5773/5773 [==============================] - 3s 588us/step - loss: 0.0370 - accuracy: 0.9896\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.2671 - accuracy: 0.9041 - val_loss: 0.0967 - val_accuracy: 0.9649\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 0.0531 - val_accuracy: 0.9832\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.0365 - val_accuracy: 0.9889\n",
      "5773/5773 [==============================] - 3s 586us/step - loss: 0.0365 - accuracy: 0.9889\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.2649 - accuracy: 0.9073 - val_loss: 0.0626 - val_accuracy: 0.9826\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 0.0575 - val_accuracy: 0.9813\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.0390 - accuracy: 0.9894 - val_loss: 0.0250 - val_accuracy: 0.9945\n",
      "5773/5773 [==============================] - 3s 584us/step - loss: 0.0250 - accuracy: 0.9945\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.2376 - accuracy: 0.9171 - val_loss: 0.0500 - val_accuracy: 0.9887\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 0.0299 - val_accuracy: 0.9926\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.0228 - val_accuracy: 0.9943\n",
      "5773/5773 [==============================] - 3s 590us/step - loss: 0.0228 - accuracy: 0.9943\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.3274 - accuracy: 0.8798 - val_loss: 0.0662 - val_accuracy: 0.9860\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 807us/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.0497 - val_accuracy: 0.9783\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.0442 - accuracy: 0.9866 - val_loss: 0.0359 - val_accuracy: 0.9903\n",
      "5773/5773 [==============================] - 3s 578us/step - loss: 0.0359 - accuracy: 0.9903\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 809us/step - loss: 0.2571 - accuracy: 0.9103 - val_loss: 0.0569 - val_accuracy: 0.9842\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 800us/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0780 - val_accuracy: 0.9734\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 802us/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 0.0347 - val_accuracy: 0.9916\n",
      "5773/5773 [==============================] - 3s 586us/step - loss: 0.0347 - accuracy: 0.9916\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 804us/step - loss: 0.6966 - accuracy: 0.7087 - val_loss: 0.5242 - val_accuracy: 0.7887\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 800us/step - loss: 0.5090 - accuracy: 0.7881 - val_loss: 0.5017 - val_accuracy: 0.7873\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 18s 798us/step - loss: 0.4823 - accuracy: 0.7974 - val_loss: 0.4627 - val_accuracy: 0.8075\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.4627 - accuracy: 0.8075\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.2588 - accuracy: 0.9108 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 804us/step - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.0487 - val_accuracy: 0.9856\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.1453 - val_accuracy: 0.9472\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.1453 - accuracy: 0.9472\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.3024 - accuracy: 0.8898 - val_loss: 0.0638 - val_accuracy: 0.9844\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 809us/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 0.0296 - val_accuracy: 0.9943\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0196 - val_accuracy: 0.9955\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.0196 - accuracy: 0.9955\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.2694 - accuracy: 0.9043 - val_loss: 0.0880 - val_accuracy: 0.9720\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0468 - val_accuracy: 0.9836\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.0337 - val_accuracy: 0.9921\n",
      "5773/5773 [==============================] - 3s 589us/step - loss: 0.0337 - accuracy: 0.9921\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 820us/step - loss: 0.2606 - accuracy: 0.9075 - val_loss: 0.0614 - val_accuracy: 0.9828\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.0568 - accuracy: 0.9834 - val_loss: 0.0341 - val_accuracy: 0.9940\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 846us/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0319 - val_accuracy: 0.9928\n",
      "5773/5773 [==============================] - 4s 680us/step - loss: 0.0319 - accuracy: 0.9928\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.2331 - accuracy: 0.9190 - val_loss: 0.0593 - val_accuracy: 0.9821\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.0475 - val_accuracy: 0.9830\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 802us/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.0179 - val_accuracy: 0.9974\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0179 - accuracy: 0.9974\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.2584 - accuracy: 0.9084 - val_loss: 0.0473 - val_accuracy: 0.9886\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 797us/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0385 - accuracy: 0.9886 - val_loss: 0.0224 - val_accuracy: 0.9953\n",
      "5773/5773 [==============================] - 3s 571us/step - loss: 0.0224 - accuracy: 0.9953\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.2938 - accuracy: 0.8931 - val_loss: 0.0657 - val_accuracy: 0.9818\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.0552 - accuracy: 0.9844 - val_loss: 0.0434 - val_accuracy: 0.9856\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0289 - accuracy: 0.9918\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.2523 - accuracy: 0.9120 - val_loss: 0.0631 - val_accuracy: 0.9842\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 805us/step - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.0574 - val_accuracy: 0.9802\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 807us/step - loss: 0.0462 - accuracy: 0.9870 - val_loss: 0.0244 - val_accuracy: 0.9954\n",
      "5773/5773 [==============================] - 3s 586us/step - loss: 0.0244 - accuracy: 0.9954\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 815us/step - loss: 0.2847 - accuracy: 0.8980 - val_loss: 0.0544 - val_accuracy: 0.9875\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.1992 - val_accuracy: 0.9300\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9871\n",
      "5773/5773 [==============================] - 3s 584us/step - loss: 0.0427 - accuracy: 0.9871\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 849us/step - loss: 0.2781 - accuracy: 0.9022 - val_loss: 0.0481 - val_accuracy: 0.9908\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 815us/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.0291 - val_accuracy: 0.9923\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 815us/step - loss: 0.0384 - accuracy: 0.9892 - val_loss: 0.0200 - val_accuracy: 0.9961\n",
      "5773/5773 [==============================] - 3s 590us/step - loss: 0.0200 - accuracy: 0.9961\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.2760 - accuracy: 0.9008 - val_loss: 0.0562 - val_accuracy: 0.9843\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.0566 - accuracy: 0.9836 - val_loss: 0.0871 - val_accuracy: 0.9708\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.0273 - accuracy: 0.9942\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.2555 - accuracy: 0.9098 - val_loss: 0.0549 - val_accuracy: 0.9825\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.0501 - accuracy: 0.9851 - val_loss: 0.0251 - val_accuracy: 0.9962\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0462 - val_accuracy: 0.9832\n",
      "5773/5773 [==============================] - 4s 651us/step - loss: 0.0462 - accuracy: 0.9832\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 835us/step - loss: 0.3944 - accuracy: 0.8575 - val_loss: 0.1688 - val_accuracy: 0.9454\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 805us/step - loss: 0.0705 - accuracy: 0.9807 - val_loss: 0.0435 - val_accuracy: 0.9904\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 807us/step - loss: 0.0542 - accuracy: 0.9848 - val_loss: 0.0388 - val_accuracy: 0.9915\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0388 - accuracy: 0.9915\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 843us/step - loss: 0.2790 - accuracy: 0.9037 - val_loss: 0.0882 - val_accuracy: 0.9733\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 802us/step - loss: 0.0552 - accuracy: 0.9850 - val_loss: 0.0902 - val_accuracy: 0.9747\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.0312 - val_accuracy: 0.9933\n",
      "5773/5773 [==============================] - 3s 581us/step - loss: 0.0312 - accuracy: 0.9933\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.2482 - accuracy: 0.9143 - val_loss: 0.0634 - val_accuracy: 0.9776\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 817us/step - loss: 0.0557 - accuracy: 0.9834 - val_loss: 0.0359 - val_accuracy: 0.9897\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 809us/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.0218 - val_accuracy: 0.9964\n",
      "5773/5773 [==============================] - 3s 582us/step - loss: 0.0218 - accuracy: 0.9964\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 832us/step - loss: 0.2750 - accuracy: 0.9013 - val_loss: 0.0622 - val_accuracy: 0.9781\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.0326 - val_accuracy: 0.9906\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0341 - val_accuracy: 0.9911\n",
      "5773/5773 [==============================] - 3s 589us/step - loss: 0.0341 - accuracy: 0.9911\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.2558 - accuracy: 0.9089 - val_loss: 0.0560 - val_accuracy: 0.9807\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0465 - val_accuracy: 0.9851\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.0217 - val_accuracy: 0.9952\n",
      "5773/5773 [==============================] - 3s 589us/step - loss: 0.0217 - accuracy: 0.9952\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.2485 - accuracy: 0.9131 - val_loss: 0.0599 - val_accuracy: 0.9867\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0500 - val_accuracy: 0.9811\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0249 - val_accuracy: 0.9947\n",
      "5773/5773 [==============================] - 4s 620us/step - loss: 0.0249 - accuracy: 0.9947\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.2561 - accuracy: 0.9085 - val_loss: 0.0604 - val_accuracy: 0.9835\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.0259 - val_accuracy: 0.9933\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.0226 - accuracy: 0.9942\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.3062 - accuracy: 0.8924 - val_loss: 0.1206 - val_accuracy: 0.9587\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.0672 - accuracy: 0.9788 - val_loss: 0.0623 - val_accuracy: 0.9816\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "5773/5773 [==============================] - 3s 590us/step - loss: 0.0426 - accuracy: 0.9854\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 831us/step - loss: 0.2684 - accuracy: 0.9083 - val_loss: 0.0453 - val_accuracy: 0.9911\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0501 - accuracy: 0.9855 - val_loss: 0.0319 - val_accuracy: 0.9926\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 820us/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.0401 - val_accuracy: 0.9888\n",
      "5773/5773 [==============================] - 3s 589us/step - loss: 0.0401 - accuracy: 0.9888\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.2654 - accuracy: 0.9084 - val_loss: 0.0685 - val_accuracy: 0.9833\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.0578 - accuracy: 0.9835 - val_loss: 0.0633 - val_accuracy: 0.9811\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0422 - accuracy: 0.9887 - val_loss: 0.0507 - val_accuracy: 0.9838\n",
      "5773/5773 [==============================] - 3s 592us/step - loss: 0.0507 - accuracy: 0.9838\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.2654 - accuracy: 0.9069 - val_loss: 0.0557 - val_accuracy: 0.9793\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 815us/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 0.0399 - val_accuracy: 0.9868\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.0273 - val_accuracy: 0.9938\n",
      "5773/5773 [==============================] - 3s 580us/step - loss: 0.0273 - accuracy: 0.9938\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.2622 - accuracy: 0.9069 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 813us/step - loss: 0.0530 - accuracy: 0.9847 - val_loss: 0.0351 - val_accuracy: 0.9883\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 0.0507 - val_accuracy: 0.9830\n",
      "5773/5773 [==============================] - 3s 584us/step - loss: 0.0507 - accuracy: 0.9830\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.2756 - accuracy: 0.9019 - val_loss: 0.0621 - val_accuracy: 0.9837\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 0.0553 - accuracy: 0.9836 - val_loss: 0.1442 - val_accuracy: 0.9520\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 808us/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 0.0277 - val_accuracy: 0.9939\n",
      "5773/5773 [==============================] - 3s 583us/step - loss: 0.0277 - accuracy: 0.9939\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2623 - accuracy: 0.9058 - val_loss: 0.0564 - val_accuracy: 0.9834\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0397 - accuracy: 0.9886 - val_loss: 0.0193 - val_accuracy: 0.9975\n",
      "5773/5773 [==============================] - 3s 599us/step - loss: 0.0193 - accuracy: 0.9975\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 820us/step - loss: 0.2499 - accuracy: 0.9125 - val_loss: 0.0595 - val_accuracy: 0.9849\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.0483 - accuracy: 0.9857 - val_loss: 0.0474 - val_accuracy: 0.9825\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 806us/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 0.0362 - val_accuracy: 0.9907\n",
      "5773/5773 [==============================] - 3s 587us/step - loss: 0.0362 - accuracy: 0.9907\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 829us/step - loss: 0.2562 - accuracy: 0.9103 - val_loss: 0.0674 - val_accuracy: 0.9801\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0522 - accuracy: 0.9852 - val_loss: 0.0296 - val_accuracy: 0.9949\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.0387 - accuracy: 0.9894 - val_loss: 0.0540 - val_accuracy: 0.9837\n",
      "5773/5773 [==============================] - 3s 582us/step - loss: 0.0540 - accuracy: 0.9837\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 830us/step - loss: 0.2664 - accuracy: 0.9097 - val_loss: 0.0666 - val_accuracy: 0.9790\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 0.0479 - val_accuracy: 0.9862\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 814us/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0256 - val_accuracy: 0.9952\n",
      "5773/5773 [==============================] - 3s 603us/step - loss: 0.0256 - accuracy: 0.9952\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 819us/step - loss: 0.3066 - accuracy: 0.8928 - val_loss: 0.0715 - val_accuracy: 0.9808\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 810us/step - loss: 0.0508 - accuracy: 0.9856 - val_loss: 0.0271 - val_accuracy: 0.9954\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0402 - accuracy: 0.9883 - val_loss: 0.0231 - val_accuracy: 0.9949\n",
      "5773/5773 [==============================] - 3s 583us/step - loss: 0.0231 - accuracy: 0.9949\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 817us/step - loss: 0.2769 - accuracy: 0.9043 - val_loss: 0.0620 - val_accuracy: 0.9848\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 784us/step - loss: 0.0558 - accuracy: 0.9844 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 739us/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
      "5773/5773 [==============================] - 3s 535us/step - loss: 0.0351 - accuracy: 0.9917\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 735us/step - loss: 0.3010 - accuracy: 0.8961 - val_loss: 0.0671 - val_accuracy: 0.9841\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 729us/step - loss: 0.0603 - accuracy: 0.9835 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 725us/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.0647 - val_accuracy: 0.9753\n",
      "5773/5773 [==============================] - 3s 516us/step - loss: 0.0647 - accuracy: 0.9753\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 749us/step - loss: 0.2658 - accuracy: 0.9093 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 736us/step - loss: 0.0576 - accuracy: 0.9840 - val_loss: 0.0476 - val_accuracy: 0.9890\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 745us/step - loss: 0.0435 - accuracy: 0.9884 - val_loss: 0.0277 - val_accuracy: 0.9952\n",
      "5773/5773 [==============================] - 3s 533us/step - loss: 0.0277 - accuracy: 0.9952\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 743us/step - loss: 0.2638 - accuracy: 0.9086 - val_loss: 0.0769 - val_accuracy: 0.9806\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 811us/step - loss: 0.0578 - accuracy: 0.9829 - val_loss: 0.0930 - val_accuracy: 0.9726\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 853us/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.4206 - val_accuracy: 0.9151\n",
      "5773/5773 [==============================] - 3s 586us/step - loss: 0.4206 - accuracy: 0.9151\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 770us/step - loss: 0.2734 - accuracy: 0.9023 - val_loss: 0.0825 - val_accuracy: 0.9774\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 738us/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0300 - val_accuracy: 0.9948\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
      "5773/5773 [==============================] - 3s 534us/step - loss: 0.0314 - accuracy: 0.9918\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 747us/step - loss: 0.2561 - accuracy: 0.9107 - val_loss: 0.0546 - val_accuracy: 0.9862\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 734us/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0415 - val_accuracy: 0.9867\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 735us/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.0571 - val_accuracy: 0.9818\n",
      "5773/5773 [==============================] - 3s 539us/step - loss: 0.0571 - accuracy: 0.9818\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 777us/step - loss: 0.2677 - accuracy: 0.9054 - val_loss: 0.0853 - val_accuracy: 0.9735\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 744us/step - loss: 0.0614 - accuracy: 0.9820 - val_loss: 0.0503 - val_accuracy: 0.9850\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 0.0344 - val_accuracy: 0.9909\n",
      "5773/5773 [==============================] - 3s 532us/step - loss: 0.0344 - accuracy: 0.9909\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 740us/step - loss: 0.2487 - accuracy: 0.9123 - val_loss: 0.0513 - val_accuracy: 0.9891\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 728us/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 0.0329 - val_accuracy: 0.9891\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 18s 776us/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 0.0208 - val_accuracy: 0.9960\n",
      "5773/5773 [==============================] - 3s 549us/step - loss: 0.0208 - accuracy: 0.9960\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 778us/step - loss: 0.3003 - accuracy: 0.8928 - val_loss: 0.0383 - val_accuracy: 0.9923\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 758us/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 0.0332 - val_accuracy: 0.9916\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 757us/step - loss: 0.0372 - accuracy: 0.9894 - val_loss: 0.0191 - val_accuracy: 0.9971\n",
      "5773/5773 [==============================] - 3s 543us/step - loss: 0.0191 - accuracy: 0.9971\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 778us/step - loss: 0.2959 - accuracy: 0.8963 - val_loss: 0.0897 - val_accuracy: 0.9706\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 749us/step - loss: 0.0731 - accuracy: 0.9759 - val_loss: 0.0702 - val_accuracy: 0.9748\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 738us/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.0719 - val_accuracy: 0.9729\n",
      "5773/5773 [==============================] - 3s 528us/step - loss: 0.0719 - accuracy: 0.9729\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 745us/step - loss: 0.2545 - accuracy: 0.9109 - val_loss: 0.0625 - val_accuracy: 0.9862\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.0461 - val_accuracy: 0.9873\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 732us/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.0431 - val_accuracy: 0.9864\n",
      "5773/5773 [==============================] - 3s 529us/step - loss: 0.0431 - accuracy: 0.9864\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 749us/step - loss: 0.2555 - accuracy: 0.9080 - val_loss: 0.1064 - val_accuracy: 0.9653\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 727us/step - loss: 0.0555 - accuracy: 0.9833 - val_loss: 0.0358 - val_accuracy: 0.9873\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 731us/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.0677 - val_accuracy: 0.9801\n",
      "5773/5773 [==============================] - 3s 524us/step - loss: 0.0677 - accuracy: 0.9801\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 750us/step - loss: 0.2556 - accuracy: 0.9114 - val_loss: 0.0628 - val_accuracy: 0.9827\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 742us/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 0.0316 - val_accuracy: 0.9947\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 738us/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.1062 - val_accuracy: 0.9616\n",
      "5773/5773 [==============================] - 3s 530us/step - loss: 0.1062 - accuracy: 0.9616\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 752us/step - loss: 0.2941 - accuracy: 0.8978 - val_loss: 0.0590 - val_accuracy: 0.9802\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 737us/step - loss: 0.0534 - accuracy: 0.9846 - val_loss: 0.0323 - val_accuracy: 0.9934\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 743us/step - loss: 0.0402 - accuracy: 0.9888 - val_loss: 0.0371 - val_accuracy: 0.9901\n",
      "5773/5773 [==============================] - 3s 533us/step - loss: 0.0371 - accuracy: 0.9901\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 755us/step - loss: 0.2710 - accuracy: 0.9050 - val_loss: 0.0544 - val_accuracy: 0.9892\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 731us/step - loss: 0.0528 - accuracy: 0.9845 - val_loss: 0.0286 - val_accuracy: 0.9947\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 735us/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0293 - val_accuracy: 0.9888\n",
      "5773/5773 [==============================] - 3s 537us/step - loss: 0.0293 - accuracy: 0.9888\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 739us/step - loss: 0.2959 - accuracy: 0.8932 - val_loss: 0.0596 - val_accuracy: 0.9842\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.0336 - val_accuracy: 0.9938\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 728us/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.0931 - val_accuracy: 0.9739\n",
      "5773/5773 [==============================] - 3s 526us/step - loss: 0.0931 - accuracy: 0.9739\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 739us/step - loss: 0.2740 - accuracy: 0.9034 - val_loss: 0.1442 - val_accuracy: 0.9492\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 735us/step - loss: 0.0515 - accuracy: 0.9847 - val_loss: 0.0320 - val_accuracy: 0.9931\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 726us/step - loss: 0.0397 - accuracy: 0.9885 - val_loss: 0.0163 - val_accuracy: 0.9978\n",
      "5773/5773 [==============================] - 3s 525us/step - loss: 0.0163 - accuracy: 0.9978\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 741us/step - loss: 0.3389 - accuracy: 0.8809 - val_loss: 0.1040 - val_accuracy: 0.9629\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 731us/step - loss: 0.0677 - accuracy: 0.9802 - val_loss: 0.0384 - val_accuracy: 0.9955\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0431 - accuracy: 0.9896 - val_loss: 0.0205 - val_accuracy: 0.9981\n",
      "5773/5773 [==============================] - 3s 541us/step - loss: 0.0205 - accuracy: 0.9981\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 751us/step - loss: 0.3035 - accuracy: 0.8930 - val_loss: 0.0499 - val_accuracy: 0.9906\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 739us/step - loss: 0.0510 - accuracy: 0.9854 - val_loss: 0.0293 - val_accuracy: 0.9942\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 738us/step - loss: 0.0379 - accuracy: 0.9891 - val_loss: 0.0253 - val_accuracy: 0.9933\n",
      "5773/5773 [==============================] - 3s 530us/step - loss: 0.0253 - accuracy: 0.9933\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 747us/step - loss: 0.2598 - accuracy: 0.9094 - val_loss: 0.0549 - val_accuracy: 0.9889\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 744us/step - loss: 0.0486 - accuracy: 0.9862 - val_loss: 0.0389 - val_accuracy: 0.9859\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 742us/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 0.0570 - val_accuracy: 0.9815\n",
      "5773/5773 [==============================] - 3s 527us/step - loss: 0.0570 - accuracy: 0.9815\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 752us/step - loss: 0.2299 - accuracy: 0.9195 - val_loss: 0.0520 - val_accuracy: 0.9847\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 740us/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.0264 - val_accuracy: 0.9961\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 741us/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.0311 - val_accuracy: 0.9914\n",
      "5773/5773 [==============================] - 3s 537us/step - loss: 0.0311 - accuracy: 0.9914\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 742us/step - loss: 0.2708 - accuracy: 0.9050 - val_loss: 0.0599 - val_accuracy: 0.9888\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 732us/step - loss: 0.0580 - accuracy: 0.9838 - val_loss: 0.0415 - val_accuracy: 0.9893\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 732us/step - loss: 0.0416 - accuracy: 0.9889 - val_loss: 0.1074 - val_accuracy: 0.9631\n",
      "5773/5773 [==============================] - 3s 519us/step - loss: 0.1074 - accuracy: 0.9631\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 743us/step - loss: 0.2689 - accuracy: 0.9072 - val_loss: 0.0610 - val_accuracy: 0.9845\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.0496 - val_accuracy: 0.9846\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 734us/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.0239 - val_accuracy: 0.9933\n",
      "5773/5773 [==============================] - 3s 522us/step - loss: 0.0239 - accuracy: 0.9933\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 763us/step - loss: 0.2807 - accuracy: 0.9032 - val_loss: 0.0960 - val_accuracy: 0.9694\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 729us/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.0888 - val_accuracy: 0.9681\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 737us/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 0.0233 - val_accuracy: 0.9966\n",
      "5773/5773 [==============================] - 3s 542us/step - loss: 0.0233 - accuracy: 0.9966\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 748us/step - loss: 0.2878 - accuracy: 0.9016 - val_loss: 0.0838 - val_accuracy: 0.9743\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0552 - accuracy: 0.9841 - val_loss: 0.0291 - val_accuracy: 0.9954\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 735us/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.0295 - val_accuracy: 0.9924\n",
      "5773/5773 [==============================] - 3s 540us/step - loss: 0.0295 - accuracy: 0.9924\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 750us/step - loss: 0.2704 - accuracy: 0.9069 - val_loss: 0.0922 - val_accuracy: 0.9719\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.0508 - val_accuracy: 0.9807\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 18s 770us/step - loss: 0.0410 - accuracy: 0.9882 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
      "5773/5773 [==============================] - 3s 538us/step - loss: 0.0453 - accuracy: 0.9862\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 751us/step - loss: 0.2639 - accuracy: 0.9080 - val_loss: 0.0667 - val_accuracy: 0.9738\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 0.0250 - val_accuracy: 0.9972\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.0379 - val_accuracy: 0.9887\n",
      "5773/5773 [==============================] - 3s 536us/step - loss: 0.0379 - accuracy: 0.9887\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 742us/step - loss: 0.2620 - accuracy: 0.9077 - val_loss: 0.1119 - val_accuracy: 0.9586\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 734us/step - loss: 0.0518 - accuracy: 0.9847 - val_loss: 0.0315 - val_accuracy: 0.9936\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 737us/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 0.0233 - val_accuracy: 0.9951\n",
      "5773/5773 [==============================] - 3s 537us/step - loss: 0.0233 - accuracy: 0.9951\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 746us/step - loss: 0.2688 - accuracy: 0.9070 - val_loss: 0.0835 - val_accuracy: 0.9734\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 736us/step - loss: 0.0517 - accuracy: 0.9856 - val_loss: 0.0298 - val_accuracy: 0.9949\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 736us/step - loss: 0.0393 - accuracy: 0.9896 - val_loss: 0.0344 - val_accuracy: 0.9894\n",
      "5773/5773 [==============================] - 3s 548us/step - loss: 0.0344 - accuracy: 0.9894\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 744us/step - loss: 0.3001 - accuracy: 0.8933 - val_loss: 0.0641 - val_accuracy: 0.9834\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 721us/step - loss: 0.0608 - accuracy: 0.9829 - val_loss: 0.0342 - val_accuracy: 0.9927\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 0.0254 - val_accuracy: 0.9945\n",
      "5773/5773 [==============================] - 3s 533us/step - loss: 0.0254 - accuracy: 0.9945\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 750us/step - loss: 0.3580 - accuracy: 0.8709 - val_loss: 0.1008 - val_accuracy: 0.9727\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.0687 - accuracy: 0.9803 - val_loss: 0.1363 - val_accuracy: 0.9438\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 734us/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.0286 - val_accuracy: 0.9934\n",
      "5773/5773 [==============================] - 3s 528us/step - loss: 0.0286 - accuracy: 0.9934\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 744us/step - loss: 0.2563 - accuracy: 0.9108 - val_loss: 0.0588 - val_accuracy: 0.9836\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 734us/step - loss: 0.0536 - accuracy: 0.9850 - val_loss: 0.0319 - val_accuracy: 0.9951\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 725us/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0389 - val_accuracy: 0.9907\n",
      "5773/5773 [==============================] - 3s 531us/step - loss: 0.0389 - accuracy: 0.9907\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 733us/step - loss: 0.2692 - accuracy: 0.9073 - val_loss: 0.0632 - val_accuracy: 0.9840\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 722us/step - loss: 0.0537 - accuracy: 0.9845 - val_loss: 0.0335 - val_accuracy: 0.9924\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 720us/step - loss: 0.0406 - accuracy: 0.9888 - val_loss: 0.0197 - val_accuracy: 0.9970\n",
      "5773/5773 [==============================] - 3s 535us/step - loss: 0.0197 - accuracy: 0.9970\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 19s 789us/step - loss: 0.2622 - accuracy: 0.9071 - val_loss: 0.0723 - val_accuracy: 0.9806\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 730us/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 0.0378 - val_accuracy: 0.9910\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 731us/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.0511 - val_accuracy: 0.9781\n",
      "5773/5773 [==============================] - 3s 522us/step - loss: 0.0511 - accuracy: 0.9781\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 18s 744us/step - loss: 0.2829 - accuracy: 0.9024 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 731us/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: 0.0335 - val_accuracy: 0.9951\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 732us/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0270 - val_accuracy: 0.9958\n",
      "5773/5773 [==============================] - 3s 522us/step - loss: 0.0270 - accuracy: 0.9958\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 732us/step - loss: 0.2642 - accuracy: 0.9082 - val_loss: 0.0533 - val_accuracy: 0.9797\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 17s 726us/step - loss: 0.0527 - accuracy: 0.9847 - val_loss: 0.0569 - val_accuracy: 0.9800\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 721us/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 0.0185 - val_accuracy: 0.9961\n",
      "5773/5773 [==============================] - 3s 525us/step - loss: 0.0185 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for feature in X.columns:\n",
    "    X_modified = X.drop(columns=[feature])\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_modified, y_one_hot, test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_modified_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_modified_test_scaled = scaler.transform(X_test)\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_modified_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_modified_train_scaled, y_train, epochs=3, batch_size=32, validation_data=(X_modified_test_scaled, y_test))\n",
    "\n",
    "    # model.fit(X_train, y_train)\n",
    "    # accuracy_dropped = model.score(X_test, y_test)\n",
    "    accuracy = 0.9959830045700073\n",
    "    loss, accuracy_dropped = model.evaluate(X_modified_test_scaled, y_test)\n",
    "    results.append((feature, accuracy - accuracy_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Model\\\\accuracy_report_without_house_and_person.csv'\n",
    "\n",
    "# Write results to CSV\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Dropped Feature', 'Accuracy Loss'])\n",
    "    for result in results:\n",
    "        csvwriter.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener=open(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Model\\\\accuracy_report_without_house_and_person.txt\",'w')\n",
    "for i in results:\n",
    "    opener.write(str(i))\n",
    "opener.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
