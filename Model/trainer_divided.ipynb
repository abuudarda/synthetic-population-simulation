{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\NHTS Data Parser\\\\HH Data Parser\\\\trippub.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_keep = ['HOUSEID', 'PERSONID',\"STRTTIME\",\"ENDTIME\",'TRVLCMIN', 'R_SEX', 'R_AGE', 'WRKCOUNT','HHVEHCNT', 'HHSIZE','EDUC','WHYTRP1S','HHFAMINC']\n",
    "final_data = pd.read_csv(file_path,usecols=columns_to_keep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateAge(age):\n",
    "    if age <=5:\n",
    "        return 1\n",
    "    elif age <= 18:\n",
    "        return 2\n",
    "    elif age <= 25:\n",
    "        return 3\n",
    "    elif age < 60:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# get the symbolic name of the gender from numerical value\n",
    "def translateSex(sex):\n",
    "    if sex == 1:\n",
    "        return 'male'\n",
    "    else:\n",
    "        return 'female'\n",
    "\n",
    "# get the race categories from numerical race values\n",
    "def translateRace(race):\n",
    "    if race == 1:\n",
    "        return 1 #white\n",
    "    elif race == 2:\n",
    "        return 2 #black\n",
    "    elif race == 4 and race ==6:\n",
    "        return 3 #native\n",
    "    elif race == 3:\n",
    "        return 6 #asian\n",
    "    elif race == 5:\n",
    "        return 7 #'pacific-islander'\n",
    "    else:\n",
    "        return 8 #'other'\n",
    "    \n",
    "def translateInc(inc):\n",
    "    if inc>=10: return 10\n",
    "    if inc<1: return 0\n",
    "    return inc   \n",
    "\n",
    "def translateTSum(ts):\n",
    "    if ts==1: return 1 #Home\n",
    "    elif ts==10: return 2 #work\n",
    "    elif ts==20: return 3 #school\n",
    "    elif ts==30: return 4 #medical\n",
    "    elif ts==40: return 5 #shopping\n",
    "    elif ts==50: return 6 #social\n",
    "    elif ts==70: return 7 #transport\n",
    "    elif ts==80: return 8 #meals\n",
    "    elif ts==97: return 9 #other\n",
    "    else : return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "final_data['R_AGE'] = final_data.apply(lambda row: translateAge(row['R_AGE']), axis=1)\n",
    "# final_data['R_RACE'] = final_data.apply(lambda row: translateRace(row['R_RACE']), axis=1)\n",
    "final_data['HHFAMINC'] = final_data.apply(lambda row: translateInc(row['HHFAMINC']), axis=1)\n",
    "final_data['WHYTRP1S'] = final_data.apply(lambda row: translateTSum(row['WHYTRP1S']), axis=1)\n",
    "# final_data['STRTTIME'] = final_data['STRTTIME'].apply(lambda x: datetime.time(hour=x // 100, minute=x % 100))\n",
    "# final_data['ENDTIME'] = final_data['ENDTIME'].apply(lambda x: datetime.time(hour=x // 100, minute=x % 100))\n",
    "# final_data['TRVLCMIN'] = final_data['TRVLCMIN'].apply(lambda x: datetime.time(hour=x // 100, minute=x % 100))\n",
    "\n",
    "#KORLAM ABAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700    17077\n",
       "1600    15211\n",
       "1500    14534\n",
       "1000    14212\n",
       "1100    13626\n",
       "        ...  \n",
       "439         1\n",
       "226         1\n",
       "221         1\n",
       "346         1\n",
       "341         1\n",
       "Name: STRTTIME, Length: 1397, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['STRTTIME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738857, 10)\n",
      "(738857,)\n",
      "(923572, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "X = final_data.drop(columns=['WHYTRP1S','HOUSEID', 'PERSONID'],axis=1)\n",
    "# X = final_data.drop(columns=['WHYTRP1S','HOUSEID', 'PERSONID','STRTTIME','ENDTIME','TRVLCMIN'],axis=1)\n",
    "y = final_data['WHYTRP1S']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(X.shape)\n",
    "num_classes =10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.11390705, -1.07630199, -0.50266214, ..., -0.1048354 ,\n",
       "        -0.6809178 ,  0.85813544],\n",
       "       [ 0.74398245,  0.68145211, -0.50266214, ...,  0.95195306,\n",
       "         0.54369188,  0.85813544],\n",
       "       [-0.30897759, -0.35594918, -0.35093417, ..., -2.21841231,\n",
       "        -2.51783233,  0.85813544],\n",
       "       ...,\n",
       "       [-1.4789332 , -1.53322481, -0.50266214, ..., -0.1048354 ,\n",
       "        -0.6809178 ,  0.85813544],\n",
       "       [ 1.66824738,  1.60229146, -0.50266214, ..., -0.1048354 ,\n",
       "         1.15599672, -0.94759634],\n",
       "       [ 1.7969425 ,  1.75382199, -0.1992062 , ..., -1.16162385,\n",
       "         0.54369188,  0.85813544]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 17s 709us/step - loss: 1.5969 - accuracy: 0.4397 - val_loss: 1.5741 - val_accuracy: 0.4465\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 1.5721 - accuracy: 0.4452 - val_loss: 1.5661 - val_accuracy: 0.4478\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 812us/step - loss: 1.5687 - accuracy: 0.4462 - val_loss: 1.5626 - val_accuracy: 0.4480\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 1.5626 - accuracy: 0.4480\n",
      "Test loss: 1.5626097917556763\n",
      "Test accuracy: 0.4480036795139313\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=3, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "# model.fit(X_train, y, epochs=3, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Model\\\\v3_oh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRTTIME</th>\n",
       "      <th>ENDTIME</th>\n",
       "      <th>TRVLCMIN</th>\n",
       "      <th>HHSIZE</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>HHFAMINC</th>\n",
       "      <th>WRKCOUNT</th>\n",
       "      <th>R_AGE</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>R_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STRTTIME  ENDTIME  TRVLCMIN  HHSIZE  HHVEHCNT  HHFAMINC  WRKCOUNT  R_AGE  \\\n",
       "0      1000     1100        60       3       0.0        10       0.0      5   \n",
       "1      1000     1100        60       3       0.0        10       0.0      5   \n",
       "2      1000     1100        60       3       0.0        10       0.0      5   \n",
       "3      1000     1100        60       2       3.0        10       3.0      4   \n",
       "4      1000     1100        60       2       3.0        10       3.0      4   \n",
       "\n",
       "   EDUC  R_SEX  \n",
       "0     3      2  \n",
       "1     3      2  \n",
       "2     3      2  \n",
       "3     1      2  \n",
       "4     1      2  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_predict=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\Model\\\\shundordata.csv\")\n",
    "data_to_predict=data_to_predict.drop(['Unnamed: 0'],axis=1)\n",
    "# data_to_predict=data_to_predict.drop(['Unnamed: 0','STRTTIME','ENDTIME','TRVLCMIN'],axis=1)\n",
    "data_to_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 578us/step\n"
     ]
    }
   ],
   "source": [
    "data_to_predict = scaler.transform(data_to_predict)\n",
    "predictions = model.predict(data_to_predict)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Activity assignment\\\\scaler_filename.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename for the CSV file\n",
    "filename = 'data.csv'\n",
    "\n",
    "# Save the NumPy array to the CSV file\n",
    "np.savetxt(filename, predictions, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'\n",
    "np.savetxt(filename, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     160854\n",
       "10    138405\n",
       "7     132897\n",
       "8     110961\n",
       "5     100756\n",
       "4      70939\n",
       "9      64388\n",
       "3      59997\n",
       "2      30177\n",
       "1      29858\n",
       "0      24340\n",
       "Name: HHFAMINC, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['HHFAMINC'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
