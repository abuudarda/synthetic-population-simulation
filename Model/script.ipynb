{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnsToUse=[\"CDIVMSAR\", \"CENSUS_D\", \"CENSUS_R\", \"DRVRCNT\", \"EDUC\", \"HHRESP\", \"HHSIZE\", \"HHSTATE\", \"HHSTFIPS\", \"HHVEHCNT\", \"HH_CBSA\", \"HH_HISP\", \"HH_RACE\", \"HOMEOWN\", \"HOUSEID\", \"HHFAMINC\", \"MSACAT\", \"MSASIZE\", \"NUMADLT\", \"PRMACT\", \"PROXY\", \"RAIL\", \"R_AGE\", \"R_AGE_IMP\", \"R_SEX\", \"R_SEX_IMP\", \"SMPLSRCE\", \"URBAN\", \"URBANSIZE\", \"URBRUR\", \"WRKCOUNT\",\"TRIPPURP\"]\n",
    "df = pd.read_csv('C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\NHTS Data Parser - Rahat\\\\HH Data Parser\\\\trippub.csv')\n",
    "X = df.drop(columns=['TRIPPURP'])\n",
    "y = df['TRIPPURP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRPMILES    float64\n",
      "TRIPPURP     object\n",
      "VMT_MILE    float64\n",
      "HHSTATE      object\n",
      "GASPRICE    float64\n",
      "HH_CBSA      object\n",
      "WTTRDFIN    float64\n",
      "TRPMILAD    float64\n",
      "OBHUR        object\n",
      "DBHUR        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_int64_columns = df.dtypes[df.dtypes != 'int64']\n",
    "print(non_int64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# X['TRIPPURP'] = label_encoder.fit_transform(X['TRIPPURP'])\n",
    "X['HHSTATE'] = label_encoder.fit_transform(X['HHSTATE'])\n",
    "X['HH_CBSA'] = label_encoder.fit_transform(X['HH_CBSA'])\n",
    "X['OBHUR'] = label_encoder.fit_transform(X['OBHUR'])\n",
    "X['DBHUR'] = label_encoder.fit_transform(X['DBHUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the target variable using LabelEncoder\n",
    "y_label_encoder = LabelEncoder()\n",
    "y_encoded = y_label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the target variable to one-hot encoded format\n",
    "num_classes = len(y_label_encoder.classes_)\n",
    "y_one_hot = pd.get_dummies(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "# X_train=X.astype('float64')\n",
    "num_classes\n",
    "# Standardize the features (optional, but often recommended for neural networks)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738857, 114)\n",
      "(738857, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.2775 - accuracy: 0.9023 - val_loss: 0.2737 - val_accuracy: 0.8950\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 18s 777us/step - loss: 0.0643 - accuracy: 0.9800 - val_loss: 0.0398 - val_accuracy: 0.9908\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 17s 747us/step - loss: 0.0496 - accuracy: 0.9850 - val_loss: 0.0303 - val_accuracy: 0.9918\n",
      "5773/5773 [==============================] - 3s 568us/step - loss: 0.0303 - accuracy: 0.9918\n",
      "Test loss: 0.030263854190707207\n",
      "Test accuracy: 0.9918360710144043\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add layers to the model\n",
    "# model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=3, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "# model.fit(X_train, y, epochs=3, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRPMILES    float64\n",
      "TRIPPURP     object\n",
      "VMT_MILE    float64\n",
      "HHSTATE      object\n",
      "GASPRICE    float64\n",
      "HH_CBSA      object\n",
      "WTTRDFIN    float64\n",
      "TRPMILAD    float64\n",
      "OBHUR        object\n",
      "DBHUR        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_int64_columns = df.dtypes[df.dtypes != 'int64']\n",
    "print(non_int64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.3711 - accuracy: 0.8671 - val_loss: 0.0900 - val_accuracy: 0.9711\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0673 - accuracy: 0.9789 - val_loss: 0.0389 - val_accuracy: 0.9880\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 23s 1ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 0.0372 - val_accuracy: 0.9906\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0372 - accuracy: 0.9906\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 837us/step - loss: 0.3065 - accuracy: 0.8907 - val_loss: 0.1022 - val_accuracy: 0.9674\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0659 - accuracy: 0.9801 - val_loss: 0.0537 - val_accuracy: 0.9822\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.0324 - val_accuracy: 0.9932\n",
      "5773/5773 [==============================] - 3s 591us/step - loss: 0.0324 - accuracy: 0.9932\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 841us/step - loss: 0.2931 - accuracy: 0.8948 - val_loss: 0.1860 - val_accuracy: 0.9318\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 824us/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.2405 - val_accuracy: 0.9302\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.0351 - val_accuracy: 0.9903\n",
      "5773/5773 [==============================] - 4s 632us/step - loss: 0.0351 - accuracy: 0.9903\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 21s 886us/step - loss: 0.3259 - accuracy: 0.8855 - val_loss: 0.0732 - val_accuracy: 0.9782\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0720 - accuracy: 0.9775 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 821us/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.1353 - val_accuracy: 0.9457\n",
      "5773/5773 [==============================] - 4s 647us/step - loss: 0.1353 - accuracy: 0.9457\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.2856 - accuracy: 0.8976 - val_loss: 0.0532 - val_accuracy: 0.9843\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 856us/step - loss: 0.0581 - accuracy: 0.9824 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 21s 910us/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.0360 - val_accuracy: 0.9880\n",
      "5773/5773 [==============================] - 4s 657us/step - loss: 0.0360 - accuracy: 0.9880\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 22s 903us/step - loss: 0.2761 - accuracy: 0.9013 - val_loss: 0.0828 - val_accuracy: 0.9678\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 849us/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.0307 - val_accuracy: 0.9941\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0483 - val_accuracy: 0.9797\n",
      "5773/5773 [==============================] - 3s 594us/step - loss: 0.0483 - accuracy: 0.9797\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2847 - accuracy: 0.8981 - val_loss: 0.0688 - val_accuracy: 0.9829\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 0.0405 - val_accuracy: 0.9865\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.0323 - val_accuracy: 0.9918\n",
      "5773/5773 [==============================] - 3s 593us/step - loss: 0.0323 - accuracy: 0.9918\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 852us/step - loss: 0.3444 - accuracy: 0.8767 - val_loss: 0.0786 - val_accuracy: 0.9763\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 849us/step - loss: 0.0777 - accuracy: 0.9753 - val_loss: 0.0694 - val_accuracy: 0.9792\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.0608 - accuracy: 0.9805 - val_loss: 0.0374 - val_accuracy: 0.9885\n",
      "5773/5773 [==============================] - 4s 614us/step - loss: 0.0374 - accuracy: 0.9885\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 835us/step - loss: 0.2806 - accuracy: 0.8989 - val_loss: 0.0613 - val_accuracy: 0.9793\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 861us/step - loss: 0.0673 - accuracy: 0.9789 - val_loss: 0.0409 - val_accuracy: 0.9872\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 21s 900us/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.2930 - val_accuracy: 0.9128\n",
      "5773/5773 [==============================] - 4s 651us/step - loss: 0.2930 - accuracy: 0.9128\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 852us/step - loss: 0.3157 - accuracy: 0.8871 - val_loss: 0.0727 - val_accuracy: 0.9755\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.0347 - val_accuracy: 0.9930\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0524 - accuracy: 0.9842 - val_loss: 0.0282 - val_accuracy: 0.9946\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0282 - accuracy: 0.9946\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.3217 - accuracy: 0.8851 - val_loss: 0.0846 - val_accuracy: 0.9739\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0642 - accuracy: 0.9800 - val_loss: 0.0293 - val_accuracy: 0.9947\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 881us/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.0265 - val_accuracy: 0.9938\n",
      "5773/5773 [==============================] - 4s 608us/step - loss: 0.0265 - accuracy: 0.9938\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 834us/step - loss: 0.3048 - accuracy: 0.8908 - val_loss: 0.0657 - val_accuracy: 0.9796\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0689 - accuracy: 0.9783 - val_loss: 0.0346 - val_accuracy: 0.9935\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 818us/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.1012 - val_accuracy: 0.9632\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.1012 - accuracy: 0.9632\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 829us/step - loss: 0.3034 - accuracy: 0.8905 - val_loss: 0.1792 - val_accuracy: 0.9313\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9753\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.0403 - val_accuracy: 0.9853\n",
      "5773/5773 [==============================] - 4s 607us/step - loss: 0.0403 - accuracy: 0.9853\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 831us/step - loss: 0.2874 - accuracy: 0.8959 - val_loss: 0.1717 - val_accuracy: 0.9418\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 824us/step - loss: 0.0678 - accuracy: 0.9784 - val_loss: 0.0507 - val_accuracy: 0.9826\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 822us/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.0312 - val_accuracy: 0.9930\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0312 - accuracy: 0.9930\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 834us/step - loss: 0.2903 - accuracy: 0.8962 - val_loss: 0.0828 - val_accuracy: 0.9717\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 0.0382 - val_accuracy: 0.9893\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 0.0629 - val_accuracy: 0.9774\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.0629 - accuracy: 0.9774\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 834us/step - loss: 0.3290 - accuracy: 0.8818 - val_loss: 0.0619 - val_accuracy: 0.9810\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0659 - accuracy: 0.9783 - val_loss: 0.0364 - val_accuracy: 0.9911\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0514 - accuracy: 0.9830 - val_loss: 0.0356 - val_accuracy: 0.9867\n",
      "5773/5773 [==============================] - 3s 593us/step - loss: 0.0356 - accuracy: 0.9867\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2858 - accuracy: 0.8988 - val_loss: 0.0917 - val_accuracy: 0.9656\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.0798 - val_accuracy: 0.9703\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.0407 - val_accuracy: 0.9858\n",
      "5773/5773 [==============================] - 3s 588us/step - loss: 0.0407 - accuracy: 0.9858\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.7845 - accuracy: 0.6567 - val_loss: 0.6528 - val_accuracy: 0.7135\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.5364 - accuracy: 0.7732 - val_loss: 0.5122 - val_accuracy: 0.7808\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.4929 - accuracy: 0.7924 - val_loss: 0.4826 - val_accuracy: 0.8027\n",
      "5773/5773 [==============================] - 3s 588us/step - loss: 0.4826 - accuracy: 0.8027\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 846us/step - loss: 0.3026 - accuracy: 0.8907 - val_loss: 0.0682 - val_accuracy: 0.9797\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.0532 - val_accuracy: 0.9810\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.1070 - val_accuracy: 0.9580\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.1070 - accuracy: 0.9580\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3069 - accuracy: 0.8919 - val_loss: 0.1044 - val_accuracy: 0.9621\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0667 - accuracy: 0.9792 - val_loss: 0.0403 - val_accuracy: 0.9891\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 0.0540 - val_accuracy: 0.9818\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0540 - accuracy: 0.9818\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 831us/step - loss: 0.3025 - accuracy: 0.8933 - val_loss: 0.1159 - val_accuracy: 0.9533\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0698 - accuracy: 0.9780 - val_loss: 0.0395 - val_accuracy: 0.9898\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 824us/step - loss: 0.0520 - accuracy: 0.9839 - val_loss: 0.0494 - val_accuracy: 0.9830\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0494 - accuracy: 0.9830\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 832us/step - loss: 0.3014 - accuracy: 0.8922 - val_loss: 0.0771 - val_accuracy: 0.9736\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0666 - accuracy: 0.9785 - val_loss: 0.0491 - val_accuracy: 0.9835\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0527 - accuracy: 0.9829 - val_loss: 0.0282 - val_accuracy: 0.9903\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0282 - accuracy: 0.9903\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 830us/step - loss: 0.2987 - accuracy: 0.8947 - val_loss: 0.0870 - val_accuracy: 0.9705\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0624 - accuracy: 0.9816 - val_loss: 0.0370 - val_accuracy: 0.9907\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0481 - accuracy: 0.9858 - val_loss: 0.0307 - val_accuracy: 0.9937\n",
      "5773/5773 [==============================] - 3s 589us/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2882 - accuracy: 0.8981 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0556 - accuracy: 0.9825 - val_loss: 0.0576 - val_accuracy: 0.9772\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.0576 - accuracy: 0.9772\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.3047 - accuracy: 0.8906 - val_loss: 0.1213 - val_accuracy: 0.9591\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0787 - accuracy: 0.9745 - val_loss: 0.1094 - val_accuracy: 0.9560\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 0.0829 - val_accuracy: 0.9699\n",
      "5773/5773 [==============================] - 3s 591us/step - loss: 0.0829 - accuracy: 0.9699\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 832us/step - loss: 0.3098 - accuracy: 0.8877 - val_loss: 0.0715 - val_accuracy: 0.9753\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 0.0422 - val_accuracy: 0.9864\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 0.0340 - val_accuracy: 0.9867\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.0340 - accuracy: 0.9867\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 843us/step - loss: 0.3034 - accuracy: 0.8898 - val_loss: 0.0581 - val_accuracy: 0.9801\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 0.0483 - val_accuracy: 0.9860\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 0.0229 - val_accuracy: 0.9968\n",
      "5773/5773 [==============================] - 4s 662us/step - loss: 0.0229 - accuracy: 0.9968\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.3395 - accuracy: 0.8764 - val_loss: 0.1308 - val_accuracy: 0.9499\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0677 - accuracy: 0.9783 - val_loss: 0.0358 - val_accuracy: 0.9935\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.0373 - val_accuracy: 0.9909\n",
      "5773/5773 [==============================] - 4s 609us/step - loss: 0.0373 - accuracy: 0.9909\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 843us/step - loss: 0.2982 - accuracy: 0.8946 - val_loss: 0.0689 - val_accuracy: 0.9778\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0623 - accuracy: 0.9812 - val_loss: 0.0331 - val_accuracy: 0.9945\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.0615 - val_accuracy: 0.9799\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0615 - accuracy: 0.9799\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 837us/step - loss: 0.3558 - accuracy: 0.8722 - val_loss: 0.1746 - val_accuracy: 0.9335\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 0.0400 - val_accuracy: 0.9871\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.0215 - val_accuracy: 0.9962\n",
      "5773/5773 [==============================] - 3s 588us/step - loss: 0.0215 - accuracy: 0.9962\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.4536 - accuracy: 0.8334 - val_loss: 0.2273 - val_accuracy: 0.9174\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.0477 - val_accuracy: 0.9895\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0645 - accuracy: 0.9812 - val_loss: 0.0670 - val_accuracy: 0.9794\n",
      "5773/5773 [==============================] - 4s 604us/step - loss: 0.0670 - accuracy: 0.9794\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 841us/step - loss: 0.3150 - accuracy: 0.8864 - val_loss: 0.0858 - val_accuracy: 0.9663\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0651 - accuracy: 0.9804 - val_loss: 0.0388 - val_accuracy: 0.9879\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0488 - accuracy: 0.9856 - val_loss: 0.0377 - val_accuracy: 0.9891\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0377 - accuracy: 0.9891\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.3481 - accuracy: 0.8759 - val_loss: 0.0772 - val_accuracy: 0.9804\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.0503 - val_accuracy: 0.9813\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.2250 - val_accuracy: 0.9259\n",
      "5773/5773 [==============================] - 4s 606us/step - loss: 0.2250 - accuracy: 0.9259\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 833us/step - loss: 0.3113 - accuracy: 0.8889 - val_loss: 0.0630 - val_accuracy: 0.9811\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 828us/step - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.0318 - val_accuracy: 0.9914\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0501 - accuracy: 0.9845 - val_loss: 0.0335 - val_accuracy: 0.9907\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0335 - accuracy: 0.9907\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 830us/step - loss: 0.2900 - accuracy: 0.8961 - val_loss: 0.1469 - val_accuracy: 0.9520\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0686 - accuracy: 0.9784 - val_loss: 0.0910 - val_accuracy: 0.9631\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9699\n",
      "5773/5773 [==============================] - 3s 593us/step - loss: 0.0868 - accuracy: 0.9699\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.2922 - accuracy: 0.8959 - val_loss: 0.2624 - val_accuracy: 0.8963\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 843us/step - loss: 0.0676 - accuracy: 0.9781 - val_loss: 0.0715 - val_accuracy: 0.9825\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0540 - accuracy: 0.9824 - val_loss: 0.1160 - val_accuracy: 0.9618\n",
      "5773/5773 [==============================] - 4s 608us/step - loss: 0.1160 - accuracy: 0.9618\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 858us/step - loss: 0.3519 - accuracy: 0.8751 - val_loss: 0.0709 - val_accuracy: 0.9822\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 843us/step - loss: 0.0682 - accuracy: 0.9795 - val_loss: 0.0630 - val_accuracy: 0.9779\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.0501 - accuracy: 0.9855 - val_loss: 0.0316 - val_accuracy: 0.9924\n",
      "5773/5773 [==============================] - 4s 608us/step - loss: 0.0316 - accuracy: 0.9924\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 853us/step - loss: 0.3413 - accuracy: 0.8808 - val_loss: 0.1093 - val_accuracy: 0.9615\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.0709 - accuracy: 0.9784 - val_loss: 0.0515 - val_accuracy: 0.9822\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 843us/step - loss: 0.0542 - accuracy: 0.9838 - val_loss: 0.0411 - val_accuracy: 0.9871\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0411 - accuracy: 0.9871\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 856us/step - loss: 0.3479 - accuracy: 0.8773 - val_loss: 0.0746 - val_accuracy: 0.9771\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0704 - accuracy: 0.9782 - val_loss: 0.0404 - val_accuracy: 0.9923\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.0669 - val_accuracy: 0.9792\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0669 - accuracy: 0.9792\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2966 - accuracy: 0.8947 - val_loss: 0.0784 - val_accuracy: 0.9747\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.0397 - val_accuracy: 0.9886\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.1363 - val_accuracy: 0.9450\n",
      "5773/5773 [==============================] - 3s 593us/step - loss: 0.1363 - accuracy: 0.9450\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2786 - accuracy: 0.8999 - val_loss: 0.0506 - val_accuracy: 0.9899\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.0674 - val_accuracy: 0.9776\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 840us/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0320 - accuracy: 0.9906\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.2827 - accuracy: 0.8992 - val_loss: 0.1368 - val_accuracy: 0.9389\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 0.0615 - accuracy: 0.9806 - val_loss: 0.0906 - val_accuracy: 0.9709\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0491 - accuracy: 0.9844 - val_loss: 0.0443 - val_accuracy: 0.9842\n",
      "5773/5773 [==============================] - 3s 592us/step - loss: 0.0443 - accuracy: 0.9842\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.3232 - accuracy: 0.8843 - val_loss: 0.1064 - val_accuracy: 0.9738\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0799 - accuracy: 0.9746 - val_loss: 0.0617 - val_accuracy: 0.9823\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0540 - accuracy: 0.9843 - val_loss: 0.0561 - val_accuracy: 0.9816\n",
      "5773/5773 [==============================] - 4s 612us/step - loss: 0.0561 - accuracy: 0.9816\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 842us/step - loss: 0.2832 - accuracy: 0.8997 - val_loss: 0.1227 - val_accuracy: 0.9591\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0533 - val_accuracy: 0.9815\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.0576 - val_accuracy: 0.9759\n",
      "5773/5773 [==============================] - 3s 603us/step - loss: 0.0576 - accuracy: 0.9759\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.2829 - accuracy: 0.8982 - val_loss: 0.0864 - val_accuracy: 0.9740\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 828us/step - loss: 0.0679 - accuracy: 0.9786 - val_loss: 0.0428 - val_accuracy: 0.9852\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.0419 - val_accuracy: 0.9851\n",
      "5773/5773 [==============================] - 4s 619us/step - loss: 0.0419 - accuracy: 0.9851\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 849us/step - loss: 0.2871 - accuracy: 0.8975 - val_loss: 0.0735 - val_accuracy: 0.9734\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0622 - accuracy: 0.9803 - val_loss: 0.0438 - val_accuracy: 0.9863\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0491 - accuracy: 0.9848 - val_loss: 0.0282 - val_accuracy: 0.9914\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0282 - accuracy: 0.9914\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 21s 835us/step - loss: 0.2907 - accuracy: 0.8953 - val_loss: 0.0677 - val_accuracy: 0.9815\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0613 - accuracy: 0.9802 - val_loss: 0.0372 - val_accuracy: 0.9908\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 828us/step - loss: 0.0476 - accuracy: 0.9849 - val_loss: 0.0614 - val_accuracy: 0.9791\n",
      "5773/5773 [==============================] - 3s 594us/step - loss: 0.0614 - accuracy: 0.9791\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 832us/step - loss: 0.3161 - accuracy: 0.8884 - val_loss: 0.0672 - val_accuracy: 0.9788\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.0632 - accuracy: 0.9809 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0494 - accuracy: 0.9853 - val_loss: 0.0341 - val_accuracy: 0.9910\n",
      "5773/5773 [==============================] - 3s 591us/step - loss: 0.0341 - accuracy: 0.9910\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 842us/step - loss: 0.2999 - accuracy: 0.8921 - val_loss: 0.1086 - val_accuracy: 0.9660\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.0497 - val_accuracy: 0.9811\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 840us/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0335 - val_accuracy: 0.9915\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0335 - accuracy: 0.9915\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.2785 - accuracy: 0.9017 - val_loss: 0.0802 - val_accuracy: 0.9741\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0624 - accuracy: 0.9804 - val_loss: 0.0420 - val_accuracy: 0.9895\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.0410 - val_accuracy: 0.9873\n",
      "5773/5773 [==============================] - 4s 606us/step - loss: 0.0410 - accuracy: 0.9873\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2828 - accuracy: 0.8998 - val_loss: 0.0672 - val_accuracy: 0.9802\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0656 - accuracy: 0.9797 - val_loss: 0.0473 - val_accuracy: 0.9858\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0505 - accuracy: 0.9846 - val_loss: 0.0500 - val_accuracy: 0.9819\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0500 - accuracy: 0.9819\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.3158 - accuracy: 0.8882 - val_loss: 0.0642 - val_accuracy: 0.9861\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0668 - accuracy: 0.9799 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.1410 - val_accuracy: 0.9503\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.1410 - accuracy: 0.9503\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 838us/step - loss: 0.2950 - accuracy: 0.8956 - val_loss: 0.0986 - val_accuracy: 0.9656\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0691 - accuracy: 0.9778 - val_loss: 0.0560 - val_accuracy: 0.9793\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.0313 - val_accuracy: 0.9894\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0313 - accuracy: 0.9894\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2842 - accuracy: 0.9001 - val_loss: 0.0760 - val_accuracy: 0.9776\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.0541 - val_accuracy: 0.9782\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0487 - val_accuracy: 0.9807\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0487 - accuracy: 0.9807\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 855us/step - loss: 0.2952 - accuracy: 0.8947 - val_loss: 0.0908 - val_accuracy: 0.9713\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 0.0387 - val_accuracy: 0.9893\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.0371 - val_accuracy: 0.9903\n",
      "5773/5773 [==============================] - 4s 604us/step - loss: 0.0371 - accuracy: 0.9903\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.2802 - accuracy: 0.8997 - val_loss: 0.0688 - val_accuracy: 0.9792\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0667 - accuracy: 0.9786 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.0498 - val_accuracy: 0.9818\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.0498 - accuracy: 0.9818\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3077 - accuracy: 0.8907 - val_loss: 0.2667 - val_accuracy: 0.9043\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.0380 - val_accuracy: 0.9915\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.0700 - val_accuracy: 0.9751\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0700 - accuracy: 0.9751\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 842us/step - loss: 0.3069 - accuracy: 0.8900 - val_loss: 0.3114 - val_accuracy: 0.8798\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0959 - accuracy: 0.9688 - val_loss: 0.1167 - val_accuracy: 0.9557\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0781 - accuracy: 0.9734 - val_loss: 0.0530 - val_accuracy: 0.9807\n",
      "5773/5773 [==============================] - 3s 599us/step - loss: 0.0530 - accuracy: 0.9807\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.2837 - accuracy: 0.9004 - val_loss: 0.0663 - val_accuracy: 0.9768\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0620 - accuracy: 0.9812 - val_loss: 0.0392 - val_accuracy: 0.9882\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.0313 - val_accuracy: 0.9922\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.0313 - accuracy: 0.9922\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.2832 - accuracy: 0.8998 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 840us/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0579 - val_accuracy: 0.9829\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.0506 - val_accuracy: 0.9832\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0506 - accuracy: 0.9832\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.3330 - accuracy: 0.8790 - val_loss: 0.0821 - val_accuracy: 0.9654\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 0.0668 - accuracy: 0.9788 - val_loss: 0.1130 - val_accuracy: 0.9537\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.0432 - val_accuracy: 0.9871\n",
      "5773/5773 [==============================] - 4s 604us/step - loss: 0.0432 - accuracy: 0.9871\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 859us/step - loss: 0.2972 - accuracy: 0.8925 - val_loss: 0.0821 - val_accuracy: 0.9672\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 872us/step - loss: 0.0615 - accuracy: 0.9807 - val_loss: 0.0302 - val_accuracy: 0.9939\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 855us/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.0295 - val_accuracy: 0.9939\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0295 - accuracy: 0.9939\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 861us/step - loss: 0.3750 - accuracy: 0.8596 - val_loss: 0.0906 - val_accuracy: 0.9721\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 853us/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.0412 - val_accuracy: 0.9878\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.0440 - val_accuracy: 0.9876\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0440 - accuracy: 0.9876\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.3039 - accuracy: 0.8930 - val_loss: 0.0767 - val_accuracy: 0.9786\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0720 - accuracy: 0.9772 - val_loss: 0.0369 - val_accuracy: 0.9928\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 0.0339 - val_accuracy: 0.9929\n",
      "5773/5773 [==============================] - 4s 607us/step - loss: 0.0339 - accuracy: 0.9929\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 834us/step - loss: 0.2594 - accuracy: 0.9079 - val_loss: 0.0543 - val_accuracy: 0.9894\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.1131 - val_accuracy: 0.9639\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 828us/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.0773 - val_accuracy: 0.9748\n",
      "5773/5773 [==============================] - 3s 603us/step - loss: 0.0773 - accuracy: 0.9748\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 841us/step - loss: 0.3117 - accuracy: 0.8887 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0703 - accuracy: 0.9780 - val_loss: 0.1002 - val_accuracy: 0.9592\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.0576 - val_accuracy: 0.9797\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0576 - accuracy: 0.9797\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 853us/step - loss: 0.2971 - accuracy: 0.8947 - val_loss: 0.0559 - val_accuracy: 0.9882\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0634 - accuracy: 0.9804 - val_loss: 0.0333 - val_accuracy: 0.9939\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.0345 - val_accuracy: 0.9914\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0345 - accuracy: 0.9914\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3134 - accuracy: 0.8857 - val_loss: 0.0645 - val_accuracy: 0.9819\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0696 - accuracy: 0.9784 - val_loss: 0.0752 - val_accuracy: 0.9782\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.0490 - val_accuracy: 0.9807\n",
      "5773/5773 [==============================] - 4s 611us/step - loss: 0.0490 - accuracy: 0.9807\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 842us/step - loss: 0.3145 - accuracy: 0.8886 - val_loss: 0.1041 - val_accuracy: 0.9642\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0715 - accuracy: 0.9770 - val_loss: 0.0810 - val_accuracy: 0.9733\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.0363 - val_accuracy: 0.9892\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0363 - accuracy: 0.9892\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 830us/step - loss: 0.3046 - accuracy: 0.8913 - val_loss: 0.0672 - val_accuracy: 0.9830\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 816us/step - loss: 0.0697 - accuracy: 0.9777 - val_loss: 0.0416 - val_accuracy: 0.9878\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 819us/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.0270 - val_accuracy: 0.9939\n",
      "5773/5773 [==============================] - 3s 591us/step - loss: 0.0270 - accuracy: 0.9939\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 833us/step - loss: 0.3258 - accuracy: 0.8846 - val_loss: 0.0873 - val_accuracy: 0.9700\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 823us/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 0.0380 - val_accuracy: 0.9929\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.0308 - val_accuracy: 0.9895\n",
      "5773/5773 [==============================] - 4s 612us/step - loss: 0.0308 - accuracy: 0.9895\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 831us/step - loss: 0.3585 - accuracy: 0.8675 - val_loss: 0.0756 - val_accuracy: 0.9830\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 824us/step - loss: 0.0720 - accuracy: 0.9782 - val_loss: 0.0961 - val_accuracy: 0.9657\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.1820 - val_accuracy: 0.9376\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.1820 - accuracy: 0.9376\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 838us/step - loss: 0.3037 - accuracy: 0.8924 - val_loss: 0.0597 - val_accuracy: 0.9848\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0618 - accuracy: 0.9821 - val_loss: 0.0467 - val_accuracy: 0.9833\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 0.0804 - val_accuracy: 0.9733\n",
      "5773/5773 [==============================] - 4s 616us/step - loss: 0.0804 - accuracy: 0.9733\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 838us/step - loss: 0.3144 - accuracy: 0.8844 - val_loss: 0.0592 - val_accuracy: 0.9828\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.0309 - val_accuracy: 0.9950\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
      "5773/5773 [==============================] - 3s 603us/step - loss: 0.0273 - accuracy: 0.9945\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 837us/step - loss: 0.2903 - accuracy: 0.8968 - val_loss: 0.0954 - val_accuracy: 0.9654\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0637 - accuracy: 0.9803 - val_loss: 0.0422 - val_accuracy: 0.9858\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0516 - accuracy: 0.9839 - val_loss: 0.0566 - val_accuracy: 0.9812\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0566 - accuracy: 0.9812\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2988 - accuracy: 0.8930 - val_loss: 0.0971 - val_accuracy: 0.9707\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0647 - accuracy: 0.9806 - val_loss: 0.0375 - val_accuracy: 0.9898\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.0225 - val_accuracy: 0.9958\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.0225 - accuracy: 0.9958\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 837us/step - loss: 0.2995 - accuracy: 0.8948 - val_loss: 0.0831 - val_accuracy: 0.9709\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.0416 - val_accuracy: 0.9881\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.0337 - val_accuracy: 0.9917\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0337 - accuracy: 0.9917\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 855us/step - loss: 0.2952 - accuracy: 0.8951 - val_loss: 0.0807 - val_accuracy: 0.9712\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0584 - accuracy: 0.9816 - val_loss: 0.0676 - val_accuracy: 0.9757\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0489 - val_accuracy: 0.9852\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0489 - accuracy: 0.9852\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 836us/step - loss: 0.2988 - accuracy: 0.8929 - val_loss: 0.0585 - val_accuracy: 0.9855\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.1468 - val_accuracy: 0.9496\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0335 - val_accuracy: 0.9901\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0335 - accuracy: 0.9901\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 831us/step - loss: 0.2724 - accuracy: 0.9027 - val_loss: 0.1034 - val_accuracy: 0.9606\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0634 - accuracy: 0.9794 - val_loss: 0.1018 - val_accuracy: 0.9581\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.0345 - val_accuracy: 0.9878\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0345 - accuracy: 0.9878\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.2685 - accuracy: 0.9035 - val_loss: 0.0570 - val_accuracy: 0.9866\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 826us/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.0417 - val_accuracy: 0.9870\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0501 - accuracy: 0.9844 - val_loss: 0.0807 - val_accuracy: 0.9686\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0807 - accuracy: 0.9686\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3044 - accuracy: 0.8934 - val_loss: 0.0571 - val_accuracy: 0.9881\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 0.0658 - accuracy: 0.9801 - val_loss: 0.0364 - val_accuracy: 0.9942\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 0.0364 - val_accuracy: 0.9910\n",
      "5773/5773 [==============================] - 3s 600us/step - loss: 0.0364 - accuracy: 0.9910\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 842us/step - loss: 0.2743 - accuracy: 0.9019 - val_loss: 0.0773 - val_accuracy: 0.9736\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0668 - accuracy: 0.9784 - val_loss: 0.0392 - val_accuracy: 0.9905\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 841us/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0273 - val_accuracy: 0.9951\n",
      "5773/5773 [==============================] - 4s 609us/step - loss: 0.0273 - accuracy: 0.9951\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 868us/step - loss: 0.2892 - accuracy: 0.8968 - val_loss: 0.0890 - val_accuracy: 0.9735\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0663 - accuracy: 0.9790 - val_loss: 0.0737 - val_accuracy: 0.9766\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0519 - accuracy: 0.9835 - val_loss: 0.0771 - val_accuracy: 0.9686\n",
      "5773/5773 [==============================] - 4s 609us/step - loss: 0.0771 - accuracy: 0.9686\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.2978 - accuracy: 0.8933 - val_loss: 0.0667 - val_accuracy: 0.9769\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.0392 - val_accuracy: 0.9917\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.0357 - val_accuracy: 0.9881\n",
      "5773/5773 [==============================] - 4s 610us/step - loss: 0.0357 - accuracy: 0.9881\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 860us/step - loss: 0.2910 - accuracy: 0.8961 - val_loss: 0.0656 - val_accuracy: 0.9791\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.0407 - val_accuracy: 0.9880\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 843us/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.0228 - val_accuracy: 0.9946\n",
      "5773/5773 [==============================] - 4s 608us/step - loss: 0.0228 - accuracy: 0.9946\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.2810 - accuracy: 0.8997 - val_loss: 0.0680 - val_accuracy: 0.9752\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 0.0508 - val_accuracy: 0.9852\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0342 - val_accuracy: 0.9911\n",
      "5773/5773 [==============================] - 4s 608us/step - loss: 0.0342 - accuracy: 0.9911\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.2853 - accuracy: 0.8964 - val_loss: 0.0598 - val_accuracy: 0.9829\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.0415 - val_accuracy: 0.9881\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.0517 - val_accuracy: 0.9818\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0517 - accuracy: 0.9818\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.3190 - accuracy: 0.8853 - val_loss: 0.0743 - val_accuracy: 0.9743\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.0448 - val_accuracy: 0.9877\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0465 - val_accuracy: 0.9872\n",
      "5773/5773 [==============================] - 3s 596us/step - loss: 0.0465 - accuracy: 0.9872\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 21s 886us/step - loss: 0.2816 - accuracy: 0.8997 - val_loss: 0.0705 - val_accuracy: 0.9798\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0647 - accuracy: 0.9795 - val_loss: 0.0380 - val_accuracy: 0.9909\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.0374 - val_accuracy: 0.9889\n",
      "5773/5773 [==============================] - 3s 601us/step - loss: 0.0374 - accuracy: 0.9889\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 837us/step - loss: 0.3354 - accuracy: 0.8851 - val_loss: 0.0899 - val_accuracy: 0.9793\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.0517 - val_accuracy: 0.9854\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.0748 - val_accuracy: 0.9740\n",
      "5773/5773 [==============================] - 3s 595us/step - loss: 0.0748 - accuracy: 0.9740\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.3049 - accuracy: 0.8912 - val_loss: 0.0792 - val_accuracy: 0.9781\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0664 - accuracy: 0.9804 - val_loss: 0.0880 - val_accuracy: 0.9665\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.0317 - val_accuracy: 0.9943\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0317 - accuracy: 0.9943\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.3077 - accuracy: 0.8903 - val_loss: 0.0784 - val_accuracy: 0.9719\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0597 - accuracy: 0.9816 - val_loss: 0.0294 - val_accuracy: 0.9947\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 0.0219 - val_accuracy: 0.9972\n",
      "5773/5773 [==============================] - 4s 607us/step - loss: 0.0219 - accuracy: 0.9972\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 848us/step - loss: 0.3629 - accuracy: 0.8705 - val_loss: 0.1201 - val_accuracy: 0.9588\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0777 - accuracy: 0.9767 - val_loss: 0.0359 - val_accuracy: 0.9961\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.0335 - val_accuracy: 0.9909\n",
      "5773/5773 [==============================] - 4s 607us/step - loss: 0.0335 - accuracy: 0.9909\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.2810 - accuracy: 0.9011 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 0.0321 - val_accuracy: 0.9937\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.0244 - val_accuracy: 0.9952\n",
      "5773/5773 [==============================] - 4s 606us/step - loss: 0.0244 - accuracy: 0.9952\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.3118 - accuracy: 0.8909 - val_loss: 0.0580 - val_accuracy: 0.9842\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0676 - accuracy: 0.9791 - val_loss: 0.0720 - val_accuracy: 0.9738\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 844us/step - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.0988 - val_accuracy: 0.9650\n",
      "5773/5773 [==============================] - 3s 604us/step - loss: 0.0988 - accuracy: 0.9650\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2926 - accuracy: 0.8964 - val_loss: 0.0817 - val_accuracy: 0.9728\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 835us/step - loss: 0.0678 - accuracy: 0.9784 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0530 - accuracy: 0.9838 - val_loss: 0.0634 - val_accuracy: 0.9771\n",
      "5773/5773 [==============================] - 4s 610us/step - loss: 0.0634 - accuracy: 0.9771\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 845us/step - loss: 0.3012 - accuracy: 0.8912 - val_loss: 0.0634 - val_accuracy: 0.9772\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 827us/step - loss: 0.0643 - accuracy: 0.9795 - val_loss: 0.0304 - val_accuracy: 0.9934\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.0991 - val_accuracy: 0.9669\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0991 - accuracy: 0.9669\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3053 - accuracy: 0.8919 - val_loss: 0.0779 - val_accuracy: 0.9733\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0632 - accuracy: 0.9795 - val_loss: 0.0459 - val_accuracy: 0.9863\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 840us/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 0.0331 - val_accuracy: 0.9923\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.0331 - accuracy: 0.9923\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 843us/step - loss: 0.4069 - accuracy: 0.8497 - val_loss: 0.0905 - val_accuracy: 0.9788\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 836us/step - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.0727 - val_accuracy: 0.9718\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.0373 - val_accuracy: 0.9874\n",
      "5773/5773 [==============================] - 4s 604us/step - loss: 0.0373 - accuracy: 0.9874\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 841us/step - loss: 0.2908 - accuracy: 0.8937 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 832us/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.0502 - val_accuracy: 0.9866\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 830us/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.0377 - val_accuracy: 0.9857\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0377 - accuracy: 0.9857\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.3369 - accuracy: 0.8787 - val_loss: 0.0804 - val_accuracy: 0.9795\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.0470 - val_accuracy: 0.9891\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 837us/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0379 - val_accuracy: 0.9881\n",
      "5773/5773 [==============================] - 3s 602us/step - loss: 0.0379 - accuracy: 0.9881\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 840us/step - loss: 0.3125 - accuracy: 0.8875 - val_loss: 0.0818 - val_accuracy: 0.9798\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 0.0417 - val_accuracy: 0.9863\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0479 - accuracy: 0.9858 - val_loss: 0.0255 - val_accuracy: 0.9950\n",
      "5773/5773 [==============================] - 4s 603us/step - loss: 0.0255 - accuracy: 0.9950\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.3160 - accuracy: 0.8865 - val_loss: 0.0677 - val_accuracy: 0.9802\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0628 - accuracy: 0.9802 - val_loss: 0.0743 - val_accuracy: 0.9715\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0495 - accuracy: 0.9845 - val_loss: 0.0441 - val_accuracy: 0.9864\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0441 - accuracy: 0.9864\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 851us/step - loss: 0.3032 - accuracy: 0.8932 - val_loss: 0.1415 - val_accuracy: 0.9521\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.0573 - val_accuracy: 0.9820\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 843us/step - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.1560 - val_accuracy: 0.9445\n",
      "5773/5773 [==============================] - 4s 606us/step - loss: 0.1560 - accuracy: 0.9445\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 850us/step - loss: 0.3069 - accuracy: 0.8896 - val_loss: 0.0823 - val_accuracy: 0.9712\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 20s 846us/step - loss: 0.0679 - accuracy: 0.9786 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 20s 846us/step - loss: 0.0543 - accuracy: 0.9831 - val_loss: 0.0575 - val_accuracy: 0.9798\n",
      "5773/5773 [==============================] - 4s 611us/step - loss: 0.0575 - accuracy: 0.9798\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 838us/step - loss: 0.2784 - accuracy: 0.9029 - val_loss: 0.0793 - val_accuracy: 0.9773\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0637 - accuracy: 0.9806 - val_loss: 0.0473 - val_accuracy: 0.9871\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.0596 - val_accuracy: 0.9827\n",
      "5773/5773 [==============================] - 3s 598us/step - loss: 0.0596 - accuracy: 0.9827\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.3055 - accuracy: 0.8905 - val_loss: 0.0970 - val_accuracy: 0.9595\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 831us/step - loss: 0.0674 - accuracy: 0.9790 - val_loss: 0.0401 - val_accuracy: 0.9905\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 829us/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0269 - accuracy: 0.9942\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 844us/step - loss: 0.2782 - accuracy: 0.9001 - val_loss: 0.0765 - val_accuracy: 0.9723\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 842us/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.0835 - val_accuracy: 0.9698\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0287 - val_accuracy: 0.9930\n",
      "5773/5773 [==============================] - 3s 599us/step - loss: 0.0287 - accuracy: 0.9930\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 839us/step - loss: 0.3000 - accuracy: 0.8914 - val_loss: 0.0757 - val_accuracy: 0.9722\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0664 - accuracy: 0.9787 - val_loss: 0.0412 - val_accuracy: 0.9902\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.0362 - val_accuracy: 0.9875\n",
      "5773/5773 [==============================] - 4s 605us/step - loss: 0.0362 - accuracy: 0.9875\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 854us/step - loss: 0.3236 - accuracy: 0.8843 - val_loss: 0.0756 - val_accuracy: 0.9830\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 840us/step - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.0446 - val_accuracy: 0.9898\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 839us/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0884 - val_accuracy: 0.9775\n",
      "5773/5773 [==============================] - 3s 597us/step - loss: 0.0884 - accuracy: 0.9775\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 21s 835us/step - loss: 0.3240 - accuracy: 0.8844 - val_loss: 0.0554 - val_accuracy: 0.9837\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 824us/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 825us/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0497 - val_accuracy: 0.9813\n",
      "5773/5773 [==============================] - 3s 599us/step - loss: 0.0497 - accuracy: 0.9813\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 841us/step - loss: 0.2928 - accuracy: 0.8938 - val_loss: 0.0624 - val_accuracy: 0.9819\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.8719 - val_accuracy: 0.7257\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 834us/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0815 - val_accuracy: 0.9762\n",
      "5773/5773 [==============================] - 3s 603us/step - loss: 0.0815 - accuracy: 0.9762\n",
      "Epoch 1/3\n",
      "23090/23090 [==============================] - 20s 847us/step - loss: 0.3422 - accuracy: 0.8744 - val_loss: 0.0924 - val_accuracy: 0.9628\n",
      "Epoch 2/3\n",
      "23090/23090 [==============================] - 19s 833us/step - loss: 0.0778 - accuracy: 0.9759 - val_loss: 0.0432 - val_accuracy: 0.9906\n",
      "Epoch 3/3\n",
      "23090/23090 [==============================] - 19s 838us/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.0491 - val_accuracy: 0.9858\n",
      "5773/5773 [==============================] - 3s 594us/step - loss: 0.0491 - accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for feature in X.columns:\n",
    "    X_modified = X.drop(columns=[feature])\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_modified, y_one_hot, test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_modified_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_modified_test_scaled = scaler.transform(X_test)\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_modified_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_modified_train_scaled, y_train, epochs=3, batch_size=32, validation_data=(X_modified_test_scaled, y_test))\n",
    "\n",
    "    # model.fit(X_train, y_train)\n",
    "    # accuracy_dropped = model.score(X_test, y_test)\n",
    "    accuracy = 0.9918360710144043\n",
    "    loss, accuracy_dropped = model.evaluate(X_modified_test_scaled, y_test)\n",
    "    results.append((feature, accuracy - accuracy_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Model\\\\accuracy_report.csv'\n",
    "\n",
    "# Write results to CSV\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Dropped Feature', 'Accuracy Loss'])\n",
    "    for result in results:\n",
    "        csvwriter.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener=open(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\Model\\\\results.txt\",'w')\n",
    "for i in results:\n",
    "    opener.write(str(i))\n",
    "opener.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
