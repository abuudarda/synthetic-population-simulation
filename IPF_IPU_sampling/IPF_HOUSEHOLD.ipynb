{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abubabu\\AppData\\Local\\Temp\\ipykernel_34820\\187016552.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df=df.fillna(df.median())\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "col_list = [\"SERIALNO\",\"SEX\", \"RAC1P\", \"AGEP\",\"SCHL\",\"HINCP\",\"VEH\",\"NP\",\"WIF\"]\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\pums\\\\temp_pums.csv\", usecols=col_list)\n",
        "\n",
        "df.head(5)\n",
        "df=df.fillna(df.median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### marginal functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_marginals(d):\n",
        "    factors = list(d.keys())\n",
        "    targets = [sorted([(k2, v2) for k2, v2 in v.items()]) for k, v in d.items()]\n",
        "    targets = np.array([[v for _, v in item] for item in targets])\n",
        "    return factors, targets\n",
        "\n",
        "def get_table(df, targets):\n",
        "    factors, target_marginals = get_target_marginals(targets)\n",
        "\n",
        "    cross_tab = pd.crosstab(df[factors[0]], [df[c] for c in factors[1:]], dropna=False)\n",
        "    shape = tuple([df[c].unique().shape[0] for c in factors])\n",
        "    print(shape)\n",
        "\n",
        "    table = cross_tab.values.reshape(shape)\n",
        "    \n",
        "    return factors, target_marginals, table\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### table = contigency table"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading data from census"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ddg = demographic_data_groups\n",
        "ddg=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\census\\\\temp_demographic.csv\")\n",
        "edg=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\census\\\\temp_economic.csv\")\n",
        "hdg=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\census\\\\temp_housing.csv\")\n",
        "sdg=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\census\\\\temp_social.csv\")\n",
        "edudg=pd.read_csv(\"C:\\\\Users\\\\abubabu\\\\Documents\\\\GitHub\\\\synthetic-population-simulation\\\\CA-data\\\\census\\\\temp_educational.csv\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### fetching margin values from demographic data groups "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_race = {\n",
        "    'asian': 'DP05_0067E',\n",
        "    'black': 'DP05_0065E',\n",
        "    'native': 'DP05_0066E',\n",
        "    'other': 'DP05_0069E',\n",
        "    'pacific-islander': 'DP05_0068E',\n",
        "    'white': 'DP05_0064E'\n",
        "}\n",
        "temp_sex = {'female': 'DP05_0003E', 'male': 'DP05_0002E'}\n",
        "temp_age = {\n",
        "    'adult': ddg.loc[ddg['id'] == 'DP05_0010E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0011E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0012E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0013E', 'value'].values[0],\n",
        "            \n",
        "    'child': ddg.loc[ddg['id'] == 'DP05_0005E', 'value'].values[0],\n",
        "\n",
        "    'senior': ddg.loc[ddg['id'] == 'DP05_0014E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0015E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0016E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0017E', 'value'].values[0],\n",
        "\n",
        "    'tenager': ddg.loc[ddg['id'] == 'DP05_0006E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0007E', 'value'].values[0] +\n",
        "            ddg.loc[ddg['id'] == 'DP05_0008E', 'value'].values[0],\n",
        "\n",
        "    'young-adult': ddg.loc[ddg['id'] == 'DP05_0009E', 'value'].values[0]\n",
        "}\n",
        "temp_inc = {\n",
        "    '0': int(edg.loc[edg['id'] == 'DP03_0076E', 'value'].values[0]),\n",
        "    '1': int(edg.loc[edg['id'] == 'DP03_0076E', 'value'].values[0]),\n",
        "    '2': int(edg.loc[edg['id'] == 'DP03_0077E', 'value'].values[0]),\n",
        "    '3': int(edg.loc[edg['id'] == 'DP03_0078E', 'value'].values[0]),\n",
        "    '4': int(edg.loc[edg['id'] == 'DP03_0079E', 'value'].values[0]),\n",
        "    '5': int(edg.loc[edg['id'] == 'DP03_0080E', 'value'].values[0]),\n",
        "    '6': int(edg.loc[edg['id'] == 'DP03_0081E', 'value'].values[0]),\n",
        "    '7': int(edg.loc[edg['id'] == 'DP03_0082E', 'value'].values[0]),\n",
        "    '8': int(edg.loc[edg['id'] == 'DP03_0083E', 'value'].values[0]),\n",
        "    '9': int(edg.loc[edg['id'] == 'DP03_0084E', 'value'].values[0]),\n",
        "    '10': int(edg.loc[edg['id'] == 'DP03_0085E', 'value'].values[0])\n",
        "\n",
        "}\n",
        "temp_veh={\n",
        "    '1' : int(hdg.loc[hdg['id'] == 'DP04_0059E', 'value'].values[0]),\n",
        "    '2' : int(hdg.loc[hdg['id'] == 'DP04_0060E', 'value'].values[0]),\n",
        "    '3' : int(hdg.loc[hdg['id'] == 'DP04_0061E', 'value'].values[0]),\n",
        "    '0' : int(hdg.loc[hdg['id'] == 'DP04_0058E', 'value'].values[0]),\n",
        "}\n",
        "\n",
        "temp_np={ #counted from pums\n",
        "    '2': 13904,\n",
        "    '1': 7603,\n",
        "    '4': 7276,\n",
        "    '3': 5979,\n",
        "    '5': 5170,\n",
        "    '6': 2328,\n",
        "    '7': 1036,\n",
        "    '8': 424,\n",
        "    '9': 288,\n",
        "    '11': 143,\n",
        "    '10': 120,\n",
        "    '15': 45,\n",
        "    '20': 40,\n",
        "    '17': 34,\n",
        "    '16': 32,\n",
        "    '12': 24,\n",
        "    '14': 14\n",
        "}\n",
        "temp_educ={\n",
        "    'Bachelor': int(edudg.loc[edudg['id'] == 'S1501_C01_005E', 'value'].values[0]) +\n",
        "                int(edudg.loc[edudg['id'] == 'S1501_C01_012E', 'value'].values[0]),\n",
        "    'Graduate': int(edudg.loc[edudg['id'] == 'S1501_C01_013E', 'value'].values[0]),\n",
        "    'High-school': int(edudg.loc[edudg['id'] == 'S1501_C01_003E', 'value'].values[0]) +\n",
        "                int(edudg.loc[edudg['id'] == 'S1501_C01_009E', 'value'].values[0]) +\n",
        "                int(edudg.loc[edudg['id'] == 'S1501_C01_010E', 'value'].values[0]),\n",
        "    'below-high': int(edudg.loc[edudg['id'] == 'S1501_C01_002E', 'value'].values[0]) +\n",
        "                int(edudg.loc[edudg['id'] == 'S1501_C01_007E', 'value'].values[0]) +\n",
        "                int(edudg.loc[edudg['id'] == 'S1501_C01_008E', 'value'].values[0]),\n",
        "    'college': int(edudg.loc[edudg['id'] == 'S1501_C01_004E', 'value'].values[0]) +\n",
        "            int(edudg.loc[edudg['id'] == 'S1501_C01_011E', 'value'].values[0])\n",
        "}\n",
        "temp_wif={\n",
        "    '0': 31913652,\n",
        "    '1': 45272984,\n",
        "    '2': 35065006,\n",
        "    '3': 8504406\n",
        "}\n",
        "margin_dict = {\n",
        "    'HINCP':temp_inc,\n",
        "    'VEH': temp_veh,\n",
        "    'NP' : temp_np,\n",
        "    'WIF': temp_wif,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11, 4, 17, 4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abubabu\\AppData\\Local\\Temp\\ipykernel_34820\\170147130.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  targets = np.array([[v for _, v in item] for item in targets])\n"
          ]
        }
      ],
      "source": [
        "f, u, X = get_table(df, margin_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "X = contigency table\\\n",
        "u = target marginals\\\n",
        "f = helper vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=np.nan_to_num(X, nan=0.0).astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_coordinates(M):\n",
        "    return list(itertools.product(*[list(range(n)) for n in M.shape]))\n",
        "\n",
        "# returns a dict with marginals for each unique value of dimention i in M\n",
        "def get_marginals(M, i):\n",
        "    coordinates = get_coordinates(M)\n",
        "    key = lambda tup: tup[0]\n",
        "    counts = [(c[i], M[c]) for c in coordinates]\n",
        "    counts = sorted(counts, key=key)\n",
        "    counts = itertools.groupby(counts, key=key)\n",
        "    counts = {k: sum([v[1] for v in g]) for k, g in counts}\n",
        "\n",
        "    return counts\n",
        "\n",
        "def get_all_marginals(M):\n",
        "    return np.array([[v for _, v in get_marginals(M, i).items()]\n",
        "                     for i in range(len(M.shape))])\n",
        "\n",
        "# returns a dict with counts for each unique value of dimention i in M\n",
        "def get_counts(M, i):\n",
        "    coordinates = get_coordinates(M)\n",
        "\n",
        "    key = lambda tup: tup[0]\n",
        "    counts = [(c[i], M[c], c) for c in coordinates]\n",
        "    counts = sorted(counts, key=key)\n",
        "    counts = itertools.groupby(counts, key=key)\n",
        "    counts = {k: [(tup[1], tup[2]) for tup in g] for k, g in counts}\n",
        "\n",
        "    return counts\n",
        "\n",
        "#ipu to update values \n",
        "def update_values(M, i, u):\n",
        "    marg = get_marginals(M, i)\n",
        "    vals = get_counts(M, i)\n",
        "    d = [[(c, n * u[k] / marg[k]) for n, c in v] for k, v in vals.items()]\n",
        "    d = itertools.chain(*d)\n",
        "    d = list(d)\n",
        "\n",
        "    return d\n",
        "\n",
        "def ipf_update(M, u):\n",
        "    for i in range(len(M.shape)):\n",
        "        values = update_values(M, i, u[i])\n",
        "        for idx, v in values:\n",
        "            # print(idx)\n",
        "            M[idx] = v\n",
        "\n",
        "    o = get_all_marginals(M)\n",
        "    d = get_deltas(o, u)\n",
        "\n",
        "    return M, d\n",
        "\n",
        "# o-t\n",
        "def get_deltas(o, t):\n",
        "    return np.array([np.linalg.norm(np.array(o[r]) - np.array(t[r]), 2) for r in range(o.shape[0])])\n",
        "\n",
        "\n",
        "def get_weights(X, max_iters=50, zero_threshold=0.0001, convergence_threshold=3, debug=False):\n",
        "    M = X.copy()\n",
        "\n",
        "    d_prev = np.zeros(len(M.shape))\n",
        "    count_zero = 0\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        # print(_,count_zero)\n",
        "        # print(u)\n",
        "        M, d_next = ipf_update(M, u)\n",
        "        d = np.linalg.norm(d_prev - d_next, 2)\n",
        "\n",
        "        if d < zero_threshold:\n",
        "            count_zero += 1\n",
        "\n",
        "        if debug:\n",
        "            print(','.join([f'{v:.5f}' for v in d_next]), d)\n",
        "        d_prev = d_next\n",
        "\n",
        "        # breaks if zero threshold triggered in 3 consecutive run\n",
        "        if count_zero >= convergence_threshold:\n",
        "            break\n",
        "\n",
        "    w = M / M.sum()\n",
        "    return M,w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abubabu\\AppData\\Local\\Temp\\ipykernel_34820\\4157681652.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array([[v for _, v in get_marginals(M, i).items()]\n"
          ]
        }
      ],
      "source": [
        "M,w = get_weights(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file=open(\"temp.txt\",'w')\n",
        "# file.write(str(M))\n",
        "M.max()\n",
        "constf=open('hhold_constrains.txt','w')\n",
        "constf.write(' '.join(str(v) for v in M.flatten()))\n",
        "constf.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b> Sampling </b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abubabu\\AppData\\Local\\Temp\\ipykernel_30296\\3899826299.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return {k: v / get_total(df, f, k) for k, v in zip(list(itertools.product(*[sorted(df[c].unique()) for c in f])), np.ravel(w))}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIALNO</th>\n",
              "      <th>AGEP</th>\n",
              "      <th>SCHL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>RAC1P</th>\n",
              "      <th>HINCP</th>\n",
              "      <th>VEH</th>\n",
              "      <th>NP</th>\n",
              "      <th>WIF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>2017000150521</td>\n",
              "      <td>young-adult</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11198</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>High-school</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20557</th>\n",
              "      <td>2019HU0390640</td>\n",
              "      <td>adult</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>male</td>\n",
              "      <td>asian</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11198</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>High-school</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11197</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>college</td>\n",
              "      <td>female</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025</th>\n",
              "      <td>2017000342692</td>\n",
              "      <td>adult</td>\n",
              "      <td>college</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42494</th>\n",
              "      <td>2021HU1041986</td>\n",
              "      <td>adult</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>female</td>\n",
              "      <td>other</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33966</th>\n",
              "      <td>2020HU0852554</td>\n",
              "      <td>senior</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28415</th>\n",
              "      <td>2020HU0110778</td>\n",
              "      <td>adult</td>\n",
              "      <td>college</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34809</th>\n",
              "      <td>2020HU0966702</td>\n",
              "      <td>tenager</td>\n",
              "      <td>High-school</td>\n",
              "      <td>female</td>\n",
              "      <td>native</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            SERIALNO         AGEP         SCHL     SEX   RAC1P  HINCP  VEH  \\\n",
              "944    2017000150521  young-adult     Graduate  female   asian      5  1.0   \n",
              "11198  2018HU0278218        adult  High-school    male   white      2  3.0   \n",
              "20557  2019HU0390640        adult     Graduate    male   asian      3  1.0   \n",
              "11198  2018HU0278218        adult  High-school    male   white      2  3.0   \n",
              "11197  2018HU0278218        adult      college  female   white      2  3.0   \n",
              "...              ...          ...          ...     ...     ...    ...  ...   \n",
              "2025   2017000342692        adult      college    male   white      7  2.0   \n",
              "42494  2021HU1041986        adult     Graduate  female   other      9  1.0   \n",
              "33966  2020HU0852554       senior     Bachelor    male   white     10  1.0   \n",
              "28415  2020HU0110778        adult      college    male   white      8  2.0   \n",
              "34809  2020HU0966702      tenager  High-school  female  native      7  2.0   \n",
              "\n",
              "         NP  WIF  \n",
              "944     1.0  2.0  \n",
              "11198  12.0  1.0  \n",
              "20557   1.0  2.0  \n",
              "11198  12.0  1.0  \n",
              "11197  12.0  1.0  \n",
              "...     ...  ...  \n",
              "2025    9.0  2.0  \n",
              "42494   1.0  2.0  \n",
              "33966   9.0  3.0  \n",
              "28415   9.0  3.0  \n",
              "34809  14.0  3.0  \n",
              "\n",
              "[10000 rows x 9 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import functools\n",
        "\n",
        "def get_sampling_weights(df, f, w):\n",
        "    get_filters = lambda df, fields, values: [df[f] == v for f, v in zip(fields, values)]\n",
        "    get_total = lambda df, fields, values: df[functools.reduce(lambda a, b: a & b, get_filters(df, fields, values))].shape[0]\n",
        "\n",
        "    return {k: v / get_total(df, f, k) for k, v in zip(list(itertools.product(*[sorted(df[c].unique()) for c in f])), np.ravel(w))}\n",
        "\n",
        "def get_samples(df, f, w, n=10000):\n",
        "    file=open(\"temp.txt\",'w')\n",
        "    weights = get_sampling_weights(df, f, w)\n",
        "    file.write(str(weights))\n",
        "    file.close()\n",
        "    s = df.apply(lambda r: weights[tuple([r[c] for c in f])], axis=1)\n",
        "    return df.sample(n=n, replace=True, weights=s)\n",
        "\n",
        "sample_df = get_samples(df, f, w)\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_df.to_csv(\"sampled_DATA.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp=sample_df.groupby(['SERIALNO'],sort=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIALNO</th>\n",
              "      <th>AGEP</th>\n",
              "      <th>SCHL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>RAC1P</th>\n",
              "      <th>HINCP</th>\n",
              "      <th>VEH</th>\n",
              "      <th>NP</th>\n",
              "      <th>WIF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>2017000150521</td>\n",
              "      <td>young-adult</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11198</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>High-school</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20557</th>\n",
              "      <td>2019HU0390640</td>\n",
              "      <td>adult</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>male</td>\n",
              "      <td>asian</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11198</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>High-school</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11197</th>\n",
              "      <td>2018HU0278218</td>\n",
              "      <td>adult</td>\n",
              "      <td>college</td>\n",
              "      <td>female</td>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18352</th>\n",
              "      <td>2019GQ0147094</td>\n",
              "      <td>young-adult</td>\n",
              "      <td>High-school</td>\n",
              "      <td>male</td>\n",
              "      <td>asian</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43176</th>\n",
              "      <td>2021HU1149480</td>\n",
              "      <td>adult</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>female</td>\n",
              "      <td>white</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38783</th>\n",
              "      <td>2021HU0404204</td>\n",
              "      <td>senior</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44667</th>\n",
              "      <td>2021HU1395044</td>\n",
              "      <td>adult</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>female</td>\n",
              "      <td>other</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14455</th>\n",
              "      <td>2018HU0849680</td>\n",
              "      <td>senior</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>male</td>\n",
              "      <td>asian</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1433 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            SERIALNO         AGEP         SCHL     SEX  RAC1P  HINCP  VEH  \\\n",
              "944    2017000150521  young-adult     Graduate  female  asian      5  1.0   \n",
              "11198  2018HU0278218        adult  High-school    male  white      2  3.0   \n",
              "20557  2019HU0390640        adult     Graduate    male  asian      3  1.0   \n",
              "11198  2018HU0278218        adult  High-school    male  white      2  3.0   \n",
              "11197  2018HU0278218        adult      college  female  white      2  3.0   \n",
              "...              ...          ...          ...     ...    ...    ...  ...   \n",
              "18352  2019GQ0147094  young-adult  High-school    male  asian      0  2.0   \n",
              "43176  2021HU1149480        adult     Bachelor  female  white      9  1.0   \n",
              "38783  2021HU0404204       senior     Bachelor  female  asian      9  0.0   \n",
              "44667  2021HU1395044        adult     Bachelor  female  other      9  2.0   \n",
              "14455  2018HU0849680       senior     Graduate    male  asian      7  1.0   \n",
              "\n",
              "         NP  WIF  \n",
              "944     1.0  2.0  \n",
              "11198  12.0  1.0  \n",
              "20557   1.0  2.0  \n",
              "11198  12.0  1.0  \n",
              "11197  12.0  1.0  \n",
              "...     ...  ...  \n",
              "18352   1.0  2.0  \n",
              "43176   6.0  1.0  \n",
              "38783   2.0  2.0  \n",
              "44667   7.0  1.0  \n",
              "14455   1.0  2.0  \n",
              "\n",
              "[1433 rows x 9 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2018HU0278218    1583\n",
              "2020HU0966702    1158\n",
              "2017000342692    1083\n",
              "2018HU0815113     850\n",
              "2020HU0852554     615\n",
              "                 ... \n",
              "2019HU1141733       1\n",
              "2020HU1068045       1\n",
              "2018HU1191249       1\n",
              "2018HU0136208       1\n",
              "2020HU0716652       1\n",
              "Name: SERIALNO, Length: 108, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_df['SERIALNO'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-tabulation of resulting sampled matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_df.to_csv(\"SAMPLE_DATA.csv\",header=True)\n",
        "#education"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "marginals remain kind of the same"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Multidimensional IPF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "8a8c870a75a2399a18da699afb8120ef3e062104a641580cdd043bc818847915"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
